:PROPERTIES:
:ID:       f9e6f01d-331c-40e9-9283-8e347646a652
:END:
#+begin_example
root@vm29653:~# docker exec -it vault /bin/vault operator init -address="http://127.0.0.1:8200" 
Unseal Key 1: gK+nvFbHJ9ZrVX6qfRpVgHZMppCzZH6cPBecZh/ieNdC
Unseal Key 2: fixdyRW29+vx+WCOjZzVOkkTuKHo+REGxymLO8o7fWrM
Unseal Key 3: 0HQLsqIL8SFb9BNIKk1W4amNQbCO4ot+9aYcQkyfyjkl
Unseal Key 4: Glsw2R5ToR2j2HyBak1UCC91bpmHmgdzeOU/lLQtJ+9T
Unseal Key 5: G5vgwLLrVRFiAH9wh/6QtITTBQXweuPLW1fa1MSVJKaj

Initial Root Token: s.41dmrkVHjUqLt8bqWtowXMn8

Vault initialized with 5 key shares and a key threshold of 3. Please securely
distribute the key shares printed above. When the Vault is re-sealed,
restarted, or stopped, you must supply at least 3 of these keys to unseal it
before it can start servicing requests.

Vault does not store the generated master key. Without at least 3 key to
reconstruct the master key, Vault will remain permanently sealed!

It is possible to generate new unseal keys, provided you have a quorum of
existing unseal keys shares. See "vault operator rekey" for more information.

root@vm29653:~# docker exec -it vault /bin/vault operator unseal -address="http://127.0.0.1:8200" 'gK+nvFbHJ9ZrVX6qfRpVgHZMppCzZH6cPBecZh/ieNdC'
Key                Value
---                -----
Seal Type          shamir
Initialized        true
Sealed             true
Total Shares       5
Threshold          3
Unseal Progress    1/3
Unseal Nonce       057a5491-f71c-27be-31f6-f2e3474379b8
Version            1.2.3
HA Enabled         false

for key in 'gK+nvFbHJ9ZrVX6qfRpVgHZMppCzZH6cPBecZh/ieNdC' 'fixdyRW29+vx+WCOjZzVOkkTuKHo+REGxymLO8o7fWrM' '0HQLsqIL8SFb9BNIKk1W4amNQbCO4ot+9aYcQkyfyjkl' 'Glsw2R5ToR2j2HyBak1UCC91bpmHmgdzeOU/lLQtJ+9T' 'G5vgwLLrVRFiAH9wh/6QtITTBQXweuPLW1fa1MSVJKaj'; do docker exec -it vault /bin/vault operator unseal -address="http://127.0.0.1:8200" $key; done

root@vm29653:~# docker exec -it vault /bin/env VAULT_TOKEN='s.41dmrkVHjUqLt8bqWtowXMn8' VAULT_ADDR="http://127.0.0.1:8200" /bin/vault secrets list
Path          Type         Accessor              Description
----          ----         --------              -----------
cubbyhole/    cubbyhole    cubbyhole_c66ae8b8    per-token private secret storage
identity/     identity     identity_917f7ae3     identity store
sys/          system       system_cce74b06       system endpoints used for control, policy and debugging

root@vm29653:~# docker exec -it vault /bin/env VAULT_TOKEN='s.41dmrkVHjUqLt8bqWtowXMn8' VAULT_ADDR="http://127.0.0.1:8200" /bin/vault secrets enable -version=2 kv
Success! Enabled the kv secrets engine at: kv/

root@vm29653:~# docker exec -it vault /bin/env VAULT_TOKEN='s.41dmrkVHjUqLt8bqWtowXMn8' VAULT_ADDR="http://127.0.0.1:8200" /bin/vault kv put kv/hello foo=world
Key              Value
---              -----
created_time     2020-02-27T23:08:00.005380439Z
deletion_time    n/a
destroyed        false
version          1

root@vm29653:~# docker exec -it vault /bin/env VAULT_TOKEN='s.41dmrkVHjUqLt8bqWtowXMn8' VAULT_ADDR="http://127.0.0.1:8200" /bin/vault kv list kv
Keys
----
hello

root@vm29653:~# docker exec -it vault /bin/env VAULT_TOKEN='s.41dmrkVHjUqLt8bqWtowXMn8' VAULT_ADDR="http://127.0.0.1:8200" /bin/vault kv get kv/hello
====== Metadata ======
Key              Value
---              -----
created_time     2020-02-27T23:08:00.005380439Z
deletion_time    n/a
destroyed        false
version          1

=== Data ===
Key    Value
---    -----
foo    world

root@vm29653:~# curl -H "X-Vault-Token: s.41dmrkVHjUqLt8bqWtowXMn8" http://127.0.0.1:8200/v1/kv/config
{"request_id":"f36ff568-6ee7-26cd-9d4e-3eeb08fa2639","lease_id":"","renewable":false,"lease_duration":0,"data":{"cas_required":false,"max_versions":0},"wrap_info":null,"warnings":null,"auth":null}

root@vm29653:~# curl -H "X-Vault-Token: s.41dmrkVHjUqLt8bqWtowXMn8" http://127.0.0.1:8200/v1/kv/data/hello
{"request_id":"01db14ce-f2c6-71ea-d6ec-5d409bb95386","lease_id":"","renewable":false,"lease_duration":0,"data":{"data":{"foo":"world"},"metadata":{"created_time":"2020-02-27T23:08:00.005380439Z","deletion_time":"","destroyed":false,"version":1}},"wrap_info":null,"warnings":null,"auth":null}

ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no -l root -fNL 8200:localhost:8200 78.108.83.111
#+end_example

* Learning
- [[https://itdraft.ru/2020/12/02/hashicorp-vault-kak-czentr-sertifikaczii-ca-vault-pki/][HashiCorp Vault как центр сертификации (CA) / Vault PKI • vault, devops, hashicorp, pki • IT Draft]]
- [[https://developer.hashicorp.com/vault/docs/internals/limits][Limits and Maximums | Vault | HashiCorp Developer]]
- [[https://learn.hashicorp.com/tutorials/vault/tokens#renew-service-tokens][Renew service tokens | Vault - HashiCorp Learn]]
- [[https://www.vaultproject.io/docs/auth/cert][TLS Certificates - Auth Methods | Vault by HashiCorp]]
- [[https://learn.hashicorp.com/tutorials/vault/tokens][Tokens | Vault - HashiCorp Learn]]
- [[https://jthan.io/blog/using-vault-for-your-openvpn-pki/][Using Vault for your OpenVPN PKI - jthan.io]]
- [[https://piotrminkowski.com/2021/12/30/vault-on-kubernetes-with-spring-cloud/][Vault on Kubernetes with Spring Cloud - Piotr's TechBlog]]
- [[https://habr.com/ru/company/nixys/blog/578870/][Взаимное автоматическое распечатывание двух Vault кластеров в Kubernetes / Хабр]]

** [[https://brian-candler.medium.com/using-hashicorp-vault-as-an-ssh-certificate-authority-14d713673c9a][Using Vault as an SSH certificate authority]]
Brian Candler

Brian Candler
·

Follow
24 min read
·
Feb 24, 2021

Have you ever come across Hashicorp’s Vault? It started life as a place to store application “secrets” (e.g. database passwords) securely, without hard-coding them in configuration files. Over time, it has grown into something much more powerful.

There are a number of ways in which users can authenticate themselves to Vault. This can be used for access control to Vault itself, such as granting the user access to specific secrets, or management access to modify data and access policies.

However, once a user has authenticated, Vault can now in turn vouch for their identity — by issuing X509 certificates, JWT identity tokens or SSH certificates — whilst securely storing the private key material needed to issue those certificates.

Vault also has its own way of managing identities: an “entity” is essentially a user, and can be linked to multiple ways to authenticate that user. You can configure groups, both internal (where membership is manually configured) and external (vouched for by an external authentication source, such as OpenID Connect).

All this turns Vault into a powerful identity management platform.

In this article, I’m going to walk through setting up a proof-of-concept deployment of Vault as an SSH certificate authority from scratch, and illustrate some things I learned along the way.

    TL;DR: you can configure Vault to authenticate users and issue SSH certificates to them, customized to their identity.

Install Vault

Start by creating a virtual machine or container⁰. I created an lxd container called “vault1” with Ubuntu 20.04, which has IP address 10.12.255.56.

Fetch the vault binary from the downloads page, and install it (beware the wrapped line below):

wget https://releases.hashicorp.com/vault/1.6.2/vault_1.6.2_linux_amd64.zipunzip vault_1.6.2_linux_amd64.zipmv vault /usr/local/sbin/vaultchown 0:0 /usr/local/sbin/vault

Create a user for vault to run as, and a data directory:

useradd -r -s /bin/false -d /var/lib/vault -M vaultmkdir /var/lib/vaultchown vault:vault /var/lib/vaultchmod 700 /var/lib/vaultmkdir /etc/vault

Create a configuration file, /etc/vault/vault-conf.hcl

storage "file" {
  path = "/var/lib/vault"
}listener "tcp" {
  address = "0.0.0.0:8200"
  tls_disable = "true"
  #tls_cert_file = ""
  #tls_key_file = ""
}cluster_addr = "http://10.12.255.56:8201"
api_addr = "http://10.12.255.56:8200"
ui = "true"
# The following setting is not recommended, but you may need
# it when running in an unprivileged lxd container
disable_mlock="true"

There are a number of choices for data storage: I decided to use the simple filesystem backend, but there are various databases supported, as well as an integrated HA cluster database based on raft.

    NOTE: for simplicity, I have configured Vault to use HTTP rather than HTTPS. This is insecure but will be fixed later.

Create a systemd unit file, /etc/systemd/system/vault.service

[Unit]
Description=Vault secret store
Documentation=https://vaultproject.io/docs/
After=network.target
ConditionFileNotEmpty=/etc/vault/vault-conf.hcl[Service]
User=vault
ExecStart=/usr/local/sbin/vault server -config=/etc/vault/vault-conf.hcl
Restart=on-failure
RestartSec=5[Install]
WantedBy=multi-user.target

Activate the service and check its status:

systemctl daemon-reload
systemctl enable --now vault
systemctl status vault

Hopefully, Vault is now running.
Initialize Vault

Before you can use Vault, you have to initialize it.

vault operator init
Error initializing: Put "https://127.0.0.1:8200/v1/sys/init": http: server gave HTTP response to HTTPS client

Our first problem is that the client by default uses HTTPS to contact Vault, but we are running with HTTP. The workaround is to set an environment variable to give the correct URL. Create a file /etc/profile.d/vault.sh

VAULT_ADDR=http://127.0.0.1:8200
export VAULT_ADDR

and source this file (read it into the shell):

source /etc/profile.d/vault.sh
vault operator init
Unseal Key 1: XJLDnI09GSN34rea8etz+naMVq4oqWLrCIGasgRI9fNV
Unseal Key 2: 4/qwf+opE4s3arYgqhSedAt1DMLUeMyJlwZUHQiUlvOP
Unseal Key 3: +gijI0wzWbTngMVKAWEtwKb+VyUk5eXsMnPjiUQG9TSf
Unseal Key 4: T/tI+AyRpNIVr1N4SEljwSq5PXgqVkntYL4I2vQB4szm
Unseal Key 5: Gpv8QdsNBOMTMaxDEz4zGdzO7E8fuWlK9bWAuR0Qt9ReInitial Root Token: s.zHYKc0I5p2kSGBaLlmOVtrgYVault initialized with 5 key shares and a key threshold of 3. Please securely distribute the key shares printed above. When the Vault is re-sealed, restarted, or stopped, you must supply at least 3 of these keys to unseal it before it can start servicing requests.Vault does not store the generated master key. Without at least 3 key to reconstruct the master key, Vault will remain permanently sealed!It is possible to generate new unseal keys, provided you have a quorum of existing unseal keys shares. See "vault operator rekey" for more information.
#

All the data in Vault is encrypted, using a master key called the “unseal” key. Initializing Vault generates this key. It breaks it into a number of “shares”, where N out of M shares are required to recover the key. The default policy is that 3 out of 5 shares are required, but you can select a different policy at initialization time using -key-threshold=<N> -key-shares=<M>

The idea behind this is to protect against someone gaining unauthorized access to the critical data in whatever backend storage you are using. To decrypt the data they will need at least N shares, and hopefully you don’t store all of them in the same place. (But it does mean that every time you need to restart Vault, you need to bring those N shares together)

Vault also generates a “root token”, which is the equivalent of a root password in Unix: when talking to the running, unsealed instance of Vault, it grants authority to access any data or configuration, and it never expires. This is just as valuable as the unseal key, for anyone who has network access to interact with Vault.

Record the unseal keys and the root token — for this proof-of-concept you can store them in a local file, but in real life you’d store them securely somewhere else.
Unseal and login

To get started, we have to unseal the vault (i.e. load in sufficient shares of the unseal key). We also need to login, using the root token, to be able to send further commands to vault.

vault operator unseal
Unseal Key (will be hidden): <enter one share>
vault operator unseal
Unseal Key (will be hidden): <enter another share>
vault operator unseal
Unseal Key (will be hidden): <enter another share>
...
Sealed          false
...vault login
Token (will be hidden): <enter the root token>
Success! You are now authenticated.

    Note: vault login stores the token, in plain text, in ~/.vault-token. In production it’s a very bad idea to do this on the vault server itself, especially with the root token, because this may expose it to an attacker. Normally you’d login from a remote client — using either vault’s web interface or another copy of the vault binary on a remote machine— and the session would be protected by HTTPS.

Now you’re authenticated to vault. You can use vault status to check the status of the server, and vault token lookup to see information about your token.
Create the SSH CA

Setting up an SSH certificate authority is remarkably easy. You can import an existing CA private key if you like, but if you don’t, it will create one for you.

vault secrets enable -path=ssh-user-ca ssh
Success! Enabled the ssh secrets engine at: ssh-user-ca/
vault write ssh-user-ca/config/ca generate_signing_key=true
Key           Value
---           -----
public_key    ssh-rsa AAAAB3N.....

This prints the CA public key to the screen. You can also retrieve it again later:

vault read -field=public_key ssh-user-ca/config/ca

Note that you can have multiple SSH CAs if you want, mounted under different paths. I’ve chosen to call this one “ssh-user-ca”. The default would be just “ssh”, matching the name of the secrets engine.
Create signing role

I’m now going to create a signing “role”. This is a set of parameters controlling how the certificates are signed. In this case, I’m going to limit it so that it can only sign certificates with principal “test” (or no principal)¹.

The role is a JSON document that I’ll paste inline using shell “heredoc” syntax.

vault write ssh-user-ca/roles/ssh-test - <<"EOH"
{
  "algorithm_signer": "rsa-sha2-256",
  "allow_user_certificates": true,
  "allowed_users": "test",
  "default_extensions": {
    "permit-pty": ""
  },
  "key_type": "ca",
  "max_ttl": "12h",
  "ttl": "12h"
}
EOH

That’s all that’s needed. We can now sign a user certificate. Remember that we’re logged in with the “root” token currently, which means we have permission to invoke anything.

You’ll need to provide an ssh public key that you want to be signed². (If you know what ssh public keys are, then you almost certainly have one that you can use)

vault write -field=signed_key ssh-user-ca/sign/ssh-test public_key=@$HOME/.ssh/id_rsa.pub >empty.certcat empty.cert
ssh-rsa-cert-v01@openssh.com AAAAHHNza....ssh-keygen -Lf empty.cert
empty.cert:
        Type: ssh-rsa-cert-v01@openssh.com user certificate
        Public key: RSA-CERT SHA256:mVV81....
        Signing CA: RSA SHA256:nqMqs.... (using rsa-sha2-256)
        Key ID: "vault-root-99557c...."
        Serial: 2810952009944311352
        Valid: from 2021-02-22T14:46:06 to 2021-02-23T02:46:36
        Principals: (none)
        Critical Options: (none)
        Extensions:
                permit-pty

ssh-keygen -Lf lets us inspect the certificate. You can see that it has no principals (since we didn’t request any). Let’s ask for principal “test” to be included:

vault write -field=signed_key ssh-user-ca/sign/ssh-test public_key=@$HOME/.ssh/id_rsa.pub valid_principals="test" >test.certssh-keygen -Lf test.cert
test.cert:
        Type: ssh-rsa-cert-v01@openssh.com user certificate
        Public key: RSA-CERT SHA256:mVV81....
        Signing CA: RSA SHA256:nqMqs.... (using rsa-sha2-256)
        Key ID: "vault-root-99557c...."
        Serial: 10087169145372651617
        Valid: from 2021-02-22T14:47:42 to 2021-02-23T02:48:12
        Principals:
                test
        Critical Options: (none)
        Extensions:
                permit-pty

(Another way is to set "default_user": "test" in the signing role, and this will be used if the request doesn’t ask for any principals).

Even with the root token, we can’t violate the limits configured into the role. If we ask for a certificate signed for principal “foo”, it fails:

vault write -field=signed_key ssh-user-ca/sign/ssh-test public_key=@$HOME/.ssh/authorized_keys valid_principals="foo"
Error writing data to ssh-user-ca/sign/ssh-test: Error making API request.URL: PUT http://127.0.0.1:8200/v1/ssh-user-ca/sign/ssh-test
Code: 400. Errors:* foo is not a valid value for valid_principals

Certificates with multiple principals can be issued: e.g. with"allowed_users": "foo,bar" then we can request a cert with “foo”, “bar”, or both.
Signing role subtleties

There are a few things I glossed over when setting up the signing role, which I’ll mention briefly (see also the SSH secret engine API documentation).

The reason for including permit-pty in default_extensions³ is that this flag is needed to permit interactive SSH logins. Otherwise, the certificate you get restricts you to running remote commands without a pseudo-tty.

The reason for setting algorithm_signer is that modern versions of OpenSSH don’t accept certificates with SHA1 signature by default. This setting tells Vault to issue SHA256 signatures instead. It still uses the same RSA key though.

Unfortunately, openssh versions prior to 7.2 don’t accept SHA256 signatures: this includes RHEL ≤ 6 and Debian ≤ 8. If you need to authenticate to those old systems, then you have to use SHA1 signatures (ssh-rsa) instead. In that case, to get recent versions of openssh to accept the old signatures as well, you’ll need to set an option in sshd_config:

CASignatureAlgorithms ^ssh-rsa

That’s not a great idea, as you’re explicitly enabling a signature type with known security weaknesses.

Fortunately, there’s a better solution: use an elliptic curve cipher for your CA. ssh-ed25519 has been supported since OpenSSH 6.5, and ecdsa-sha2-nistp256/384/521 since OpenSSH 5.7.

Vault can sign certificates with these ciphers, but it won’t generate a non-RSA key. You can work around this by generating and importing the key yourself.
Login with the certificate

Now, you can test using this certificate to authenticate to a host. It could be the same one, or a different host.

On the target host, create a user called “test” to match the principal in the certificate:

useradd -m test -s /bin/bash

Add this line to /etc/ssh/sshd_config:

TrustedUserCAKeys /etc/ssh/ssh_ca.pub

Install the CA public key in that location:

vault read -field=public_key ssh-user-ca/config/ca >/etc/ssh/ssh_ca.pub

To pick up the changes, systemctl restart ssh.

On the client machine where you’re logging in from, and where you have your private key (id_rsa), take the certificate issued above which includes the “test” principal, and write it to ~/.ssh/id_rsa-cert.pub. Now you should be able to login as the “test” user:

ssh test@vault1
Welcome to Ubuntu 20.04.2 LTS (GNU/Linux 4.15.0-128-generic x86_64)
...
test@vault1:~$

Note that you didn’t have to put anything in ~/.ssh/authorized_keys on the target host. This is what makes this approach so powerful: it centralises policy, and avoids having to deploy individual public keys to individual accounts. Eventually, you can set AuthorizedKeysFile none to disable ~/.ssh/authorized_keys entirely.
Debugging login problems

If it doesn’t work, sometimes it can be hard to see why not.

What I recommend is that on the target system, you start a one-shot instance of sshd in debugging mode, bound to a different port:

/usr/sbin/sshd -p 99 -d

and then connect from a client with verbose logging:

ssh -p 99 -vvv test@vault1

That was how I found the signing problem which required rsa-sha2–256:

check_host_cert: certificate signature algorithm ssh-rsa: signature algorithm not supported

Avoiding the Confused Deputy

So far, we’ve got a cool API-driven SSH certificate signer, which protects the private key. Up to this point, we’ve done everything with the “root” token. Vault also lets us create tokens with limited privileges, so that we could have a token that can sign SSH certificates but do nothing else.

We limited the ssh role so that it would only issue certificates with user “test”. We could create separate roles for other users, or we could create a role that can sign any certificate:

  "allowed_users": "*",

But either way, we have a problem. We don’t want Alice to be able to get a certificate that lets her log in as “bob”, and vice versa.

Your first thought might be to put some sort of middleware in front of Vault, which decides who gets what certificate and forwards the validated request. There are a couple of problems with this.

Firstly, the middleware would have some sort of super-token which allows it to sign certificates for anyone. We’d have to be very careful that the token did not leak.

Secondly, Alice would have to prove her identity to the middleware somehow. Alice might discover a way to persuade or reconfigure the middleware to sign a certificate for “bob”. This is known as the “confused deputy problem”.

What we really need is a way for each user to prove their identity to Vault, and for Vault to issue only the permitted certificate. Fortunately, Vault lets us do this in a straightforward manner.
SSH roles

Here’s a simple company policy we’re going to implement. Alice is an administrator, and she’s allowed to get a certificate with principal “alice” or “root” (or both). Bob is a regular user, and is only allowed to get a certificate with principal “bob”.

So our first step is to create some roles, which allow signing for administrators and regular users. To avoid having to make separate roles for every user, we’re going to use a template to reference some metadata on the identity which says what their allowed ssh_username is. Don’t worry, we’ll get to this shortly.

vault write ssh-user-ca/roles/ssh-user - <<"EOH"
{
  "algorithm_signer": "rsa-sha2-256",
  "allow_user_certificates": true,
  "allowed_users": "{{identity.entity.metadata.ssh_username}}",
  "allowed_users_template": true,
  "allowed_extensions": "permit-pty,permit-agent-forwarding,permit-X11-forwarding",
  "default_extensions": {
     "permit-pty": "",
     "permit-agent-forwarding": ""
  },
  "key_type": "ca",
  "max_ttl": "12h",
  "ttl": "12h"
}
EOHvault write ssh-user-ca/roles/ssh-admin - <<"EOH"
{
  "algorithm_signer": "rsa-sha2-256",
  "allow_user_certificates": true,
  "allowed_users": "root,{{identity.entity.metadata.ssh_username}}",
  "allowed_users_template": true,
  "allowed_extensions": "permit-pty,permit-agent-forwarding,permit-X11-forwarding,permit-port-forwarding",
  "default_extensions": {
     "permit-pty": "",
     "permit-agent-forwarding": ""
  },
  "key_type": "ca",
  "max_ttl": "12h",
  "ttl": "12h"
}
EOH

These roles are very similar; the ssh-admin role includes “root” in allowed_users, and also allows some additional certificate extensions.
Policies

In Vault, the permissions that you grant to users are controlled by “policies”. A policy grants rights to do a particular kind of action on a given resource, and then policies are assigned to users or groups.

We can create policies which permit signing of SSH certificates with a particular role⁴:

vault policy write ssh-user - <<"EOH"
path "ssh-user-ca/sign/ssh-user" {
  capabilities = ["update"]
  denied_parameters = {
    "key_id" = []
  }
EOHvault policy write ssh-admin - <<"EOH"
path "ssh-user-ca/sign/ssh-admin" {
  capabilities = ["update"]
  denied_parameters = {
    "key_id" = []
  }
}
EOH

In short: anyone that we grant the “ssh-user” policy to, can sign certificates according to the “ssh-user” role in our “ssh-user-ca” certificate authority. Similarly for the “ssh-admin” policy and the “ssh-admin” role.
Identity management part 1: userpass

Now we move onto Vault’s identity management.

To keep this simple, we will start with the “userpass” authentication mechanism. As its name suggests, users prove their identity with a bog-standard username and password. (We know this is a poor way of proving identity, but we will swap it out later)

Let’s enable the userpass auth mechanism, and create user accounts for alice and bob:

vault auth enable userpassvault write auth/userpass/users/alice password=tcpip123vault write auth/userpass/users/bob password=xyzzyvault list auth/userpass/users
Keys
----
alice
bob
#

That was easy enough.

Now it’s time to login as alice. We’ll no longer be root, so make sure you kept a copy of the root token somewhere. (Alternatively, you can do this on a completely separate machine, where VAULT_ADDR points to the IP address or DNS name of your vault server).

vault login -method=userpass username=alice password=tcpip123
Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run "vault login" again. Future Vault requests will automatically use this token.Key                    Value
---                    -----
token                  s.3EU0uqq5CbVdP1nGPmlssj8M
token_accessor         ZZt5EpWzxlqPA9OVSUXBCysU
token_duration         768h
token_renewable        true
token_policies         ["default"]
identity_policies      []
policies               ["default"]
token_meta_username    alicevault token lookup
accessor            ZZt5EpWzxlqPA9OVSUXBCysU
creation_time       1614016636
creation_ttl        768h
display_name        userpass-alice
entity_id           11238cf6-074d-680a-3920-0f25d4c72670
...vault read identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670
Key                    Value
---                    -----
aliases                [map[canonical_id:11238cf6-074d-680a-3920-0f25d4c72670 creation_time:2021-02-22T17:57:16.318812652Z id:83874876-ded0-00f7-7971-ee63b7495bfa last_update_time:2021-02-22T17:57:16.318812652Z merged_from_canonical_ids:<nil> metadata:<nil> mount_accessor:auth_userpass_bbcef7b5 mount_path:auth/userpass/ mount_type:userpass name:alice]]
creation_time          2021-02-22T17:57:16.318801957Z
direct_group_ids       []
disabled               false
group_ids              []
id                     11238cf6-074d-680a-3920-0f25d4c72670
inherited_group_ids    []
last_update_time       2021-02-22T17:57:16.318801957Z
merged_entity_ids      <nil>
metadata               <nil>
name                   entity_a5aeeb8b
namespace_id           root
policies               <nil>

You can see that alice has access to the system policy “default”. This is applied to every account, unless you explicitly withhold it, and it grants a few basic rights such as users being able to read their own details.

In order to sign certs, we’ll need to grant her the policy “ssh-admin” as well. We’ll also need to set the “ssh_username” metadata item.

You can see that as a side-effect of logging in as “alice”, Vault has created an “entity” — a user record identified by a UUID — and linked it to her userpass login. Entities are powerful, because there might be several different ways that Alice can authenticate to the system, and we can link them all to the same entity. The links are called “entity aliases”: the userpass name “alice” is just one of perhaps multiple aliases to this entity record.

Entities give us a central place to apply policies for a user, when we want the user to have those rights regardless of what mechanism they used to authenticate. Entities also give us a convenient place onto which metadata can be attached⁵. Someone who logs into Vault with username “alice” might not necessarily use “alice” as their username when logging in via SSH — maybe it’s “alice1”. That’s why we kept ssh_username as a separate piece of metadata.

Alice doesn’t have permission to alter her own policies or metadata (which is a good thing!) Let’s confirm that while we’re still logged in under her credentials:

vault write identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670 - <<"EOH"
{
  "metadata": {
    "ssh_username": "alice1"
  },
  "policies": ["ssh-admin"]
}
EOH
Error writing data to identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670: Error making API request.URL: PUT http://127.0.0.1:8200/v1/identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670
Code: 403. Errors:* 1 error occurred:
        * permission denied

Therefore, we need to log back into Vault as “root”

vault login - <root_token.txt
Success! You are now authenticated.
...
vault write identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670 - <<"EOH"
{
  "metadata": {
    "ssh_username": "alice1"
  },
  "policies": ["ssh-admin"]
}
EOH
Success! Data written to: identity/entity/id/11238cf6-074d-680a-3920-0f25d4c72670

(For more details, see identity API docs)

Now login again as alice, and see if she can sign her own certificate:

vault login -method=userpass username=alice password=tcpip123
Success! You are now authenticated.
...
policies               ["default" "ssh-admin"]
...vault write -field=signed_key ssh-user-ca/sign/ssh-admin public_key=@$HOME/.ssh/id_rsa.pub valid_principals="alice1" >alice1.certssh-keygen -Lf alice1.cert
alice1.cert:
        Type: ssh-rsa-cert-v01@openssh.com user certificate
        Public key: RSA-CERT SHA256:mVV81....
        Signing CA: RSA SHA256:nqMqs.... (using rsa-sha2-256)
        Key ID: "vault-userpass-alice-99557...."
        Serial: 10773352969806096173
        Valid: from 2021-02-22T18:05:55 to 2021-02-23T06:06:25
        Principals:
                alice1
        Critical Options: (none)
        Extensions:
                permit-agent-forwarding
                permit-pty

Yay! But if she tries to sign a certificate with principal “bob”, or to sign a certificate using the ssh-test role, she can’t:

vault write -field=signed_key ssh-user-ca/sign/ssh-admin public_key=@$HOME/.ssh/id_rsa.pub valid_principals="bob"
...
Code: 400. Errors:* bob is not a valid value for valid_principalsvault write -field=signed_key ssh-user-ca/sign/ssh-test public_key=@$HOME/.ssh/id_rsa.pub
...
Code: 403. Errors:* 1 error occurred:
        * permission denied

We have the bare bones of an identity management platform.

To tidy this up a bit, rather than applying the “ssh-admin” policy directly to the user entity for Alice, we could create a group, apply the policy to the group, and make Alice a member of that group.
Management UI

By the way, if you’re getting fed up of using the CLI to manage users, there’s always Vault’s built-in web interface. This is particularly useful when you start managing groups. Just point your browser at http://x.x.x.x:8200 and login (for now with the root token).
Looking at the entity alias which connects userpass name “alice” to this entity
Identity management part 2: OpenID Connect

Userpass is rather limiting. Nobody wants to rely on passwords for authentication, unless you’re using some two-factor authentication as well (which is available in the commercial Vault Enterprise Plus version, and possibly third-party plugins)

Robust authentication is hard. In my opinion, authentication is best left to the experts. I suggest you use a cloud service like Google or Azure AD or Github to perform authentication — they can enforce 2FA using a wide range of different mechanisms like SMS, TOTP and FIDO U2F keys.

But in that case, what’s Vault for? Well firstly, remember that Vault separates authentication from identity. If someone has both a Google account and an Azure AD account, you can link them both to the same entity in Vault. (This other blog post has a good explanation and diagrams; I found it after I started writing this one).

But more importantly, you’re separating authentication from authorization. You can use Google to prove Alice’s identity, whilst your local Vault database maintains metadata and group information which says what Alice is allowed to do. There are commercial middleware services like 0Auth and Okta that can do that for you, but with Vault you can control it yourself.

All that’s needed now is to link Vault to your chosen identity provider(s), so that Alice can prove her identity via one of these cloud providers.

Since everyone has a Gmail account, let’s go straight ahead and authenticate against Google. This isn’t a primer in OpenID Connect, so from this point on I’m going to assume you know the fundamentals of that.

    Note: Vault has separate configuration for authentication against Google Cloud Platform (GCP) and Google accounts and Google Workspace. The latter is what uses OpenID Connect.

    If you want to play with this without using Google or any other cloud authentication provider, you can run a local instance of Dex.

Enable OIDC authentication

    Doc references: JWT/OIDC auth method, API, OIDC provider setup

vault auth enable -path=google oidc
Success! Enabled oidc auth method at: google/

Setup on the Google side: this is copy-paste from the docs, plus some notes I added in italics.

    Visit the Google API Console.
    Create or a select a project.
    Create a new credential via Credentials > Create Credentials > OAuth Client ID.
    Configure the OAuth Consent Screen. Select type “external” unless you have a Google Workspace account. Add scopes “email”, “profile”, “openid”. Application Name is required. Save.
    Back to Create Credentials > OAuth Client Id. Select application type: “Web Application”.
    Configure Authorized Redirect URIs. (For now, add http://localhost:8250/oidc/callback and http://vault.example.com:8200/ui/vault/auth/google/oidc/callback — where “vault.example.com” is some name that resolves to your container’s IP address, in the local /etc/hosts file if necessary)
    Save client ID and secret.

Since the scopes requested are not “sensitive”, you can push your app to “Production” without further ado — but this requires your redirect URIs to use the https:// scheme (except for the localhost one).

Now configure OIDC on Vault:

vault write auth/google/config - <<EOF
{
    "oidc_discovery_url": "https://accounts.google.com",
    "oidc_client_id": "your_client_id",
    "oidc_client_secret": "your_client_secret",
    "default_role": "standard"
}
EOF

(There is a separate provider_config section which can be added if you have a Google Workspace account, and can be used to retrieve group memberships)

Create the authentication role — this is where you can control how to map claims to metadata. You can also include other requirements, such as certain claims which must be present with certain values (“bound_claims”)

vault write auth/google/role/standard - <<EOF
{
  "allowed_redirect_uris": ["http://vault.example.com:8200/ui/vault/auth/google/oidc/callback","http://localhost:8250/oidc/callback"],
  "user_claim": "sub",
  "oidc_scopes": ["profile","email"],
  "claim_mappings": {
    "name": "name",
    "nickname": "nickname",
    "email": "email"
  }
}
EOF

Now at last you can attempt to login:

vault login -method=oidc -path=google
Complete the login via your OIDC provider. Launching browser to:https://accounts.google.com/o/oauth2/v2/auth?client_id=....&nonce=....&redirect_uri=http%3A%2F%2Flocalhost%3A8250%2Foidc%2Fcallback&response_type=code&scope=openid+profile+email&state=....

If you do this on a laptop/desktop, where VAULT_ADDR points to your vault server, then it should redirect you into a browser⁶, where you can select your Google account, and then send a code back to vault login, which then exchanges that code for a Vault token. At which point you see:

Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run "vault login" again. Future Vault requests will automatically use this token.Key                  Value
---                  -----
...
policies             ["default"]
token_meta_email     xxxx@gmail.com
token_meta_name      Alice Sample
token_meta_role      standard

You can get more info on the token you got:

vault token lookup
...
entity_id  4254a4d7-1e74-fdbf-b44b-697c3383ff7a
...
meta       map[email:xxxx@gmail.com name:Alice Sample role:standard]vault read identity/entity/id/4254a4d7-1e74-fdbf-b44b-697c3383ff7a
...
metadata   <nil>

What’s happened is that as before, a new entity has been created. This fresh entity has no policy that allows SSH certificate generation, nor any ssh_username metadata.

But what if we know that this particular Google user is actually our Alice? There’s a solution for that: we can “merge” the two entities together, so that we have a single entity with two aliases, instead of two entities each with one alias.

# Login with the root token again
vault list identity/entity/id
Keys
----
11238cf6-074d-680a-3920-0f25d4c72670
4254a4d7-1e74-fdbf-b44b-697c3383ff7avault write identity/entity/merge from_entity_ids="4254a4d7-1e74-fdbf-b44b-697c3383ff7a" to_entity_id="11238cf6-074d-680a-3920-0f25d4c72670"
Success! Data written to: identity/entity/mergevault list identity/entity/id
Keys
----
11238cf6-074d-680a-3920-0f25d4c72670

“And the two shall become one”.

Back to the session where we’d logged in with OpenIDC. Can we get a certificate for alice? We still have a token:

vault write -field=signed_key ssh-user-ca/sign/ssh-admin public_key=@$HOME/.ssh/id_rsa.pub valid_principals="alice1" >alice1.cert
Error writing data to ssh-user-ca/sign/ssh-admin: Error making API request.URL: PUT http://10.12.255.56:8200/v1/ssh-user-ca/sign/ssh-admin
Code: 400. Errors:* template '{{identity.entity.metadata.ssh_username}}' could not be rendered -> no entity found

Ah, the token we had doesn’t have the metadata (because we merged the entities after Alice had logged in). All we need to do is login again:

vault login -method=oidc -path=google
Complete the login via your OIDC provider. Launching browser to:https://accounts.google.com/o/oauth2/v2/auth?client_id=....&nonce=....&redirect_uri=http%3A%2F%2Flocalhost%3A8250%2Foidc%2Fcallback&response_type=code&scope=openid+profile+email&state=....Success! You are now authenticated. The token information displayed below is already stored in the token helper. You do NOT need to run "vault login" again. Future Vault requests will automatically use this token.Key                  Value
---                  -----
token                s.ul7UzNBCDUcXEvMvniPUAC3N
token_accessor       vw5pq6RNwcl3PFQDpQaEE18v
token_duration       768h
token_renewable      true
token_policies       ["default"]
identity_policies    ["ssh-admin"]
policies             ["default" "ssh-admin"]
token_meta_role      standardvault write -field=signed_key ssh-user-ca/sign/ssh-admin public_key=@$HOME/.ssh/id_rsa.pub valid_principals="alice1" >alice1.certssh-keygen -Lf alice1.cert
alice1.cert:
        Type: ssh-rsa-cert-v01@openssh.com user certificate
        Public key: RSA-CERT SHA256:mVV81....
        Signing CA: RSA SHA256:nqMqs.... (using rsa-sha2-256)
        Key ID: "vault-google-11368...."
        Serial: 16887243150350464400
        Valid: from 2021-02-23T16:42:45 to 2021-02-24T04:43:15
        Principals:
                alice1
        Critical Options: (none)
        Extensions:
                permit-agent-forwarding
                permit-pty

Yes!! We traded our OIDC proof of identity for an ssh certificate!
The user experience (CLI)

Setting this up might have seemed painful. But really there are just two steps for the end user:

vault login -method=oidc -path=google
vault write ...as above...# After which they can do:
# ssh user@somehost.example.com

That’s a two-line shell script to login and fetch the certificate. They need a copy of the vault binary as well, but that’s a simple download.

There is supposed to be a helper command:

vault ssh -mount-point=ssh-user-ca -role=ssh-admin -mode=ca user@somehost.example.com

Unfortunately there’s a problem with this:

failed to sign public key ~/.ssh/id_rsa.pub: Error making API request.URL: PUT http://10.12.255.56:8200/v1/ssh-user-ca/sign/ssh-admin
Code: 400. Errors:* extensions [permit-user-rc] are not on allowed list

vault ssh requests all possible SSH certificate extensions, and it can’t be configured to do otherwise. There’s a github issue for this.

Never mind. The two-liner isn’t so bad.

    UPDATE: I wrote a helper program vault-ssh-agent-login which authenticates using OIDC, generates a private key, gets Vault to sign a certificate, and then inserts the pair into ssh-agent. You don’t need any private key on disk at all!

The user experience (web UI)

It’s even possible for users to get their key signed via the Vault web UI. This could be useful in an emergency if they can’t install the vault client locally.

It’s useful to enable your preferred auth method(s) as tabs in the UI login page, which you can do by setting their “listing visibility” flag:

vault auth tune -listing-visibility=unauth userpass/vault auth tune -listing-visibility=unauth -description="Google Account" google/

    UPDATE: this feature is currently broken for OIDC logins in Vault 1.10.0, but hopefully will be fixed in 1.10.1.

It’s also helpful⁷ to widen the signing policy permissions slightly:

vault policy write ssh-admin - <<"EOH"
path "ssh-user-ca/roles" {
  capabilities = ["list"]
}
path "ssh-user-ca/config/zeroaddress" {
  capabilities = ["read"]
}
path "ssh-user-ca/sign/ssh-admin" {
  capabilities = ["update"]
}
EOH

Now a user can go to http://vault.example.com:8200 and login:
Vault UI login page

Then they can navigate to their ssh role and paste in their public key:
Vault UI: sign key

Principals are selected under “More options”. The signed certificate is then displayed and can be copied to the clipboard.
Tying up the security loose ends
Secure communication with HTTPS

The main thing I punted on initially was Transport Layer Security (TLS). Without this, tokens and secrets can be sniffed on the wire, and clients can be unknowingly redirected to imposter sites.

To enable TLS, you just need to give Vault a private key and a corresponding certificate containing its hostname and/or IP address.

Probably the best solution is to get a free public certificate issued by LetsEncrypt⁸ (using a client such as certbot, dehydrated, acme.sh etc). This means that your clients will already trust the CA which signed it. You’ll have to use a domain name, rather than IP address, in the URL that you use to access Vault (which is good practice anyway).

However, there is another interesting option: you can also set up your own X509 CA using Vault. Let’s do this for fun.

vault secrets enable pkivault secrets tune -max-lease-ttl=175200h pkivault write -field=certificate pki/root/generate/internal common_name="ca.vault.local" ttl=175200h >/etc/vault/vault-cacert.pem

We have generated an X509 certificate authority, with a 20-year root certificate. Inspect the certificate like this:

openssl x509 -in /etc/vault/vault-cacert.pem -noout -text
...
        Issuer: CN = ca.vault.local
        Validity
            Not Before: Feb 24 09:53:52 2021 GMT
            Not After : Feb 19 09:54:21 2041 GMT
...

Next create a role that permits the signing of certificates (in this case, “any domain”, for up to 1 year):

vault write pki/roles/anycert allowed_domains="*" allow_subdomains=true allow_glob_domains=true max-ttl=8760h

Finally, generate a key and certificate pair:

vault write pki/issue/anycert common_name="vault.example.com" alt_names="vault.example.com" ip_sans="10.12.255.56,127.0.0.1" ttl=8760hKey                 Value
---                 -----
certificate         -----BEGIN CERTIFICATE-----
MIIDW...
-----END CERTIFICATE-----
expiration          1645696653
issuing_ca          -----BEGIN CERTIFICATE-----
...
-----END CERTIFICATE-----
private_key         -----BEGIN RSA PRIVATE KEY-----
...
-----END RSA PRIVATE KEY-----
private_key_type    rsa
serial_number       66:23:c7:....

That gives us everything we need:

    Certificate: copy everything from -----BEGIN CERTIFICATE------ to -----END CERTIFICATE----- inclusive to /etc/vault/vault-cert.pem
    Issuing CA certificate: this is the same as vault-cacert.pem you already generated
    Private key: copy this to /etc/vault/vault-key.pem and set permissions so it’s only readable by the vault user:
    chmod 400 /etc/vault/vault-key.pem
    chown vault:vault /etc/vault/vault-key.pem

As before, you can inspect the certificate using openssl x509 -in /etc/vault/vault-cert.pem -noout -text

Now change /etc/vault/vault-conf.hcl to enable TLS:

storage "file" {
  path = "/var/lib/vault"
}listener "tcp" {
  address = "0.0.0.0:8200"
  #tls_disable = "true"
  tls_cert_file = "/etc/vault/vault-cert.pem"
  tls_key_file = "/etc/vault/vault-key.pem"
}cluster_addr = "https://10.12.255.56:8201"
api_addr = "https://10.12.255.56:8200"
ui = "true"
# The following setting is not recommended, but you may need
# it when running in an unprivileged lxd container
disable_mlock="true"

Change /etc/profile.d/vault.sh to use the new client config. Notice that it also needs to be told which root CA certificate to use to validate the server certificate.

VAULT_ADDR=https://127.0.0.1:8200
export VAULT_ADDR
VAULT_CACERT=/etc/vault/vault-cacert.pem
export VAULT_CACERT

Now restart vault and pick up the new client config:

systemctl restart vaultsource /etc/profile.d/vault.sh

At this point you should be able to talk to vault using HTTPS. Because it has been restarted, the first thing you’ll need to do is unseal it.

vault statusvault operator unseal
vault operator unseal
vault operator unseal

Now you’re back up and running, but properly secured by TLS!

An obvious follow-up is to get Vault to issue X509 certificates to users, just like we issued user SSH certificates. This is left as an exercise for the reader.
Vault hardening

For running Vault in production, there are a number of things which you should do, as described in the Vault production hardening tutorial.

I’ll emphasise just one thing here: the root token is the ultimate tool which enables access to all secret data in Vault, and allows all policy and configuration changes. You need to avoid using it for day-to-day operations.

Once you have proper user authentication set up, you can create an administrators group with suitable access policies, put trusted administrators in that group, and then destroy the root token completely (by revoking it). Don’t worry about locking yourself out: you can always generate a new root token later by using the unseal keys.
Conclusion

Vault has evolved from a secret storage system into a powerful identity management platform. This article has demonstrated authenticating to Vault using username/password and OpenID Connect, issuing user SSH certificates tied to that identity, and issuing X509 server certificates.

[⁰] A production deployment of Vault should use dedicated hardware. This is because it’s easy to attack a VM from the hypervisor side, including reading its memory where the unseal key resides.

[¹] The “principals” in a certificate are SSH’s concept of “identity”. The default policy of sshd is that in order to login as user “foo”, your certificate must contain “foo” as one of its principals. You can override this policy, e.g. with AuthorizedPrincipalsFile or AuthorizedPrincipalsCommand.

[²] When generating X509 certificates, Vault can generate a fresh private key to go with the certificate. Oddly, it doesn’t offer this for SSH certificates.

[³] The documentation is ambiguous about how you apply multiple extensions in default_extensions.

[⁴] The policy grant required to sign an SSH key is not well documented, but testing shows that the “update” permission on the signer is all you need. Denying the “key_id” parameter forbids users from choosing their own certificate key ID, which appears in SSH log files

[⁵] Actually, you can set policies directly on userpass entries, but you cannot set metadata on userpass entries — which is why we have to set it on the associated ‘entity’. But this is better anyway, assuming we want Alice to be able to sign ssh certs regardless of which mechanism she used to authenticate herself.

[⁶] vault login has a built-in webserver to accept the OIDC response code at http://localhost:8250. In principle it’s possible to do the OIDC dance without a local webserver: set the redirect URL as “urn:ietf:wg:oauth:2.0:oob” or “urn:ietf:wg:oauth:2.0:oob:auto”, which in Google requires defining the client as a “Desktop App”. The web browser will then display the response code (as plain text or JSON respectively), rather than redirecting, and you can copy-paste it back to the client. However vault login doesn’t support this, and it may be Google-specific anyway.

[⁷] If you don’t do this, the user will have to manually change the URL bar to /ui/vault/secrets/ssh-user-ca/sign/ssh-admin after logging in, to sign a certificate.

[⁸] LetsEncrypt certificates need to be rotated every 90 days, but fortunately you can get Vault to re-read its certificate files without restarting and unsealing, by sending it a SIGHUP.
Ssh
Certificate
X509
Ssh Keys
Vault

Brian Candler
Written by Brian Candler
66 Followers
More from Brian Candler
Brian Candler

Brian Candler
Interpreting Prometheus metrics for Linux disk I/O utilization
Prometheus is a metrics collection system, and its node_exporter exposes a rich range of system metrics.
10 min read·Jan 28, 2021

Brian Candler

Brian Candler
Functional Programing illustrated in Python: Part 1
Simple function composition
3 min read·Oct 20, 2020

Brian Candler

Brian Candler
Linstor: networked storage without the complexity
With step-by-step guide to deployment under Ubuntu 18.04
10 min read·Jan 26, 2021

Brian Candler

Brian Candler
Using Vault as an OpenID Connect Identity Provider
In a previous article I wrote about using Hashicorp Vault as an SSH certificate authority. As of version 1.9, Vault has gained the ability…
11 min read·Dec 13, 2021

See all from Brian Candler
Recommended from Medium
Stefanie Lai

Stefanie Lai

in

Better Programming
Improve Cluster Monitoring With Network Mapping in Grafana
A deep dive into obtaining network maps and correlating IP with cluster workloads to speed up debugging
·6 min read·Jan 12

DevOps Diva/o

DevOps Diva/o
DevSecOps: Implement security checks on Gitlab
Continuous Integration/Continuous Deployment (CI/CD) pipelines are becoming increasingly popular for automating the software development…
·7 min read·Feb 3

Lists
Staff Picks
346 stories·106 saves
Stories to Help You Level-Up at Work
19 stories·88 saves
Self-Improvement 101
20 stories·148 saves
Productivity 101
20 stories·166 saves
Nick Fothergill

Nick Fothergill

in

TechieLife
How To: Create a multi-node object storage cluster!
Object storage is the cloud-native file service used by modern web apps. It's used for storing large amounts of unstructured data. Unlike…
·6 min read·Feb 15

StringMeteor

StringMeteor

in

Level Up Coding
Run a Kubernetes cluster on Apple Silicon Mac with kind
How to set up a Kubernetes cluster inside a Docker container on a Mac in just a few commands
·9 min read·Jan 30

Sung Kim

Sung Kim

in

Geek Culture
Enable SSH Access to WSL from a Remote Computer
Setup SSH Server on Windows Subsystems for Linux (Ubuntu) on Windows 11 and Enable SSH Access to WSL from a Remote Computer
·9 min read·Jan 5

Vinayak Pandey

Vinayak Pandey

in

AWS Tip
Accessing Private EKS Cluster From Your Local Machine Using SSM Port Forwarding
In this post, we’ll see how we can access a private EKS cluster from our local machine using SSM Port Forwarding.
·2 min read·Mar 12

See more recommendations

Help

Status

Writers

Blog

Careers

Privacy

Terms

About

Text to speech

Teams


** [[https://blog.thomas.maurice.fr/posts/vault-jwt-authentication/][Authenticate your services with Vault and JWTs]]
📅 Jan 17, 2020
 ·  ☕ 7 min read

    🏷️
    #golang
    #vault
    #security

Sometimes, you may want your services to be able to talk to each other in an authenticated manner, and even perform some authorization. This is not easy to do and you might have scratched your head a bunch about how to do it. In this post I’m going to show you how to do something like this using hashicorp’s Vault. At the end of this post you’ll be able to issue and validate authorization tokens to make sure your services communicate in an authenticated and secure manner.
What are JWTs ?

JWT, or JSON Web Tokens, are tokens that are signed by a central authority that encapsulate authorization information. This website can help debugging your tokens.

A JWT is comprised of 3 parts

    Header
    Payload
    Signature

The header gives you a bunch of infos about the algorithm used, the key id used to sign the token and so on. The payload is the actual encoded auth data that you care about and the signature is used to validate the token.
Setup Vault

We are going to demonstrate that with a dev vault, so first start a vault server in a separate terminal.

$ vault server -dev-root-token-id=token -dev

In another terminal

export VAULT_ADDR=http://localhost:8200
export VAULT_TOKEN=token

Create a Vault policy

We will need to create a policy to allow the account (that we will create right after) to perform some basic operations on Vault. For the purpose of this article we are going to create a read only policy on the whole Vault. You obviously do not want to do that in an actual production environment.

echo "path \"*\" {capabilities = [\"read\"]}" | vault policy write readonly -
Success! Uploaded policy: readonly

Create the OIDC issuer

To create the OIDC issuer, do

$ vault write identity/issuer/config issuer=http://localhost:8200

This will be used to populate the issuer field of your tokens.

You will need then to create a key to sign your tokens:

$ vault write identity/oidc/key/key algorithm=ES256 allowed_client_ids='*'
Success! Data written to: identity/oidc/key/key

Alright now we had a key that will sign our tokens. Note that in a real production environment you will need to have a key per environment (dev/staging/prod and so on) and will need to individually allow client ID (which we talk about later) to be signed by your key.

You then need to create something called a role in Vault. Which will map to the app you want to authenticate against. In this example we will assume that our app is called demo, you will have to create it as follows (so it is signed with the key created above):

$ vault write identity/oidc/role/demo name=demo key=key
Success! Data written to: identity/oidc/role/demo

Good! No we need to create a user to authenticate.
Create the AppRole

An AppRole is a Vault authentication backend. You can see it as something similar to a username/password authentication, but intended for services instead of actual human users.

Enable the approle authentication backend:

$ vault auth enable approle
Success! Enabled approle auth method at: approle/

Now create the actual approle, it will be called demo-approle:

$ vault write auth/approle/role/demo-approle role_name=demo-approle policies=readonly
Success! Data written to: auth/approle/role/demo-approle

Then you will need to get two pieces of information, the roleid and the secretid for the approle. These are the equivalent of the username and the password to authenticate yourself.

$ secret_id=$(vault write -force -format=json auth/approle/role/demo-approle/secret-id | jq -r .data.secret_id)
$ role_id=$(vault read -format=json auth/approle/role/demo-approle/role-id | jq -r .data.role_id)
$ echo $role_id $secret_id
ca9f0470-8d1f-4464-2635-25f02b9407d7 f91a7c31-dc06-2b24-20fd-e9f5867c32a8

Your values will be different.
Create the entity and map it to the AppRole

Now that we have created the approle, we need to map it to an internal Vault entity, you need to do that because several entities can be mapped to various authentication backends, like userpass or if you use something like Google or what not. So first, create the entity and save it for later:

entity_id=$(vault write -format=json identity/entity name=demo |jq .data.id -r)
$ echo $entity_id
c957656f-0872-766c-3517-83b787672f84

Now you finally need to create an entity alias to make the link between the entity and the approle authentication backend (that is tedious I know but bear with me i swear it is worth it). Retrieve the accessor, which is the internal Vault reference to your approle authentication backend:

$ accessor=$(vault auth list -format=json | grep 'auth_approle' | tr -d " " | tr -d , | cut -d ":" -f 2 | tr -d \")
$ echo $accessor
auth_approle_91098819

Now finally (y e s f i n a l l y) create the alias:

$ vault write identity/entity-alias name=demo canonical_id=$entity_id mount_accessor=$accessor
Key             Value
---             -----
canonical_id    c957656f-0872-766c-3517-83b787672f84
id              a2d067d6-229b-6580-d714-35a01ba62864

Aight. Everything is setup now.
Log in as the AppRole

Now all you need to do is to log into Vault using the approle, then issue a token:

$ token=$(vault write -format=json auth/approle/login role_id=$role_id secret_id=$secret_id | jq -r .auth.client_token)
$ export VAULT_TOKEN=$token
$ echo $token
s.ohsNR1DIo6sVr8gG8hsRsk1Y

You are now logged into Vault as your approle ! Check it by running:

vault token lookup 
Key                 Value
---                 -----
accessor            Tc6riT70kLnepiW3CC0rEkBj
creation_time       1579287446
creation_ttl        768h
display_name        approle
entity_id           f1be740b-8b4f-4369-a019-bc6ef3f8e963
expire_time         2020-02-18T18:57:26.707866969Z
explicit_max_ttl    0s
id                  s.ohsNR1DIo6sVr8gG8hsRsk1Y
issue_time          2020-01-17T18:57:26.707866723Z
meta                map[role_name:demo-approle]
num_uses            0
orphan              true
path                auth/approle/login
policies            [default readonly]
renewable           true
ttl                 767h58m57s
type                service

Issue a token

Finally you can issue a token:

$ vault read identity/oidc/token/demo
Key          Value
---          -----
client_id    waqwjTM57B7ANxhw7CketPy1WJ
token        eyJhbGciOiJFUzI1NiIsImtpZCI6Ijk2MmNiZTk3LWYzY2EtMTVjMy0wNDJkLTYxZTQzMWMxOTRlMCJ9.eyJhdWQiOiJ3YXF3alRNNTdCN0FOeGh3N0NrZXRQeTFXSiIsImV4cCI6MTU3OTM3NDAwOCwiaWF0IjoxNTc5Mjg3NjA4LCJpc3MiOiJodHRwOi8vbG9jYWxob3N0OjgyMDAvdjEvaWRlbnRpdHkvb2lkYyIsIm5hbWVzcGFjZSI6InJvb3QiLCJzdWIiOiJmMWJlNzQwYi04YjRmLTQzNjktYTAxOS1iYzZlZjNmOGU5NjMifQ.OSVQHaIS9kgzdckNgsneDorR7BzE9i6JajOsBKIoByGuSMd5MTyPcu4nwv9GGAgips_mMk9dYTzckCGDcR8gXQ
ttl          24h

You can now use this token to identify to a service !

Let’s unpack the token a bit using the debugger. The headers read

{
  "alg": "ES256",
  "kid": "962cbe97-f3ca-15c3-042d-61e431c194e0"
}

The is not much about it, it specifies the signature algorithm used and the key id used to sign the token, more on that later.

The body of the token reads the following:

{
  "aud": "waqwjTM57B7ANxhw7CketPy1WJ",
  "exp": 1579374008,
  "iat": 1579287608,
  "iss": "http://localhost:8200/v1/identity/oidc",
  "namespace": "root",
  "sub": "f1be740b-8b4f-4369-a019-bc6ef3f8e963"
}

Here you have a bunch of infos about the identity of the token bearer:

    exp is the expiration time of the token
    iat is the issuance time
    iss is the issuer
    aud is the intended audience of the token, namely the demo OIDC role you created above
    sub is the subject of the token, namely the identity of the bearer. If you pay attention, this is the same UUID as the one referenced in the entity_id field of the vault token lookup command.

You can now identify who’s token you are looking at !

If you use Vault, you can also add more custom fields, such as group membership and other arbitrary things, more info on that here.
Verifying the tokens

Now you need to be able to verify the tokens. I will not expand on how to do the authorization, that’s your logic, and your problem, same for the expiration and issuer verification. However you need to be able to verify the signature of the token to establish that the token:

    Comes from whom it says it comes from
    Is signed by a key owned by whom it says it comes from

Vault exposes an unauthenticated endpoint that allows you to retrieve the public part of the signing keys used for the tokens, which you can access the following way

$ curl localhost:8200/v1/identity/oidc/.well-known/keys| jq .
{
  "keys": [
    {
      "use": "sig",
      "kty": "EC",
      "kid": "962cbe97-f3ca-15c3-042d-61e431c194e0",
      "crv": "P-256",
      "alg": "ES256",
      "x": "Ui3tAkTBb-dudDOyCyIQCfNz_1xG7ByoyJJwrEhBUFw",
      "y": "mj68rHTcy121ojJCjHJ88uRCgNF0CF90nPfHGu-YnwI"
    }
  ]
}

If you pay attention and fluently speak UUID, you will obviously notice that 962cbe97-f3ca-15c3-042d-61e431c194e0 is the kid present in the header of the token we have previously issued.

This way you can verify that the signature is valid. Note that Vault implements the openID discovery protocol which can give you access to even more information.
Wrap up

I hope that will be useful to you to use Vault as an OIDC provider for your services ! :)

* Misc

- [[https://github.com/channable/vaultenv][channable / vaultenv]]
- [[https://github.com/Caiyeon/goldfish][Caiyeon/goldfish: A HashiCorp Vault UI written with VueJS and Vault native Go API]]
- [[https://github.com/adobe/cryptr][adobe/cryptr: Cryptr: a GUI for Hashicorp's Vault]]
- [[https://github.com/grahamc/pass-vault][grahamc/pass-vault: pass, but backed by vault]]
- [[https://github.com/xbglowx/vault-kv-mv][xbglowx/vault-kv-mv: Easily move Hashicorp Vault keys to different paths]]
- [[https://github.com/hashicorp/envconsul][hashicorp/envconsul: Launch a subprocess with environment variables using data from @HashiCorp Consul and Vault.]]
- [[https://github.com/mvisonneau/strongbox][mvisonneau/strongbox: Securely store secrets at rest using Hashicorp Vault]]
- [[https://github.com/PsyanticY/vaultfs][PsyanticY/vaultfs: Hashicorp Vault fuse filesystem]]
- [[https://www.nginx.com/blog/protecting-ssl-private-keys-nginx-hashicorp-vault/][Protecting SSL Private Keys in NGINX with HashiCorp Vault - NGINX]]
- [[https://github.com/hashicorp/consul-template][hashicorp/consul-template: Template rendering, notifier, and supervisor for @HashiCorp Consul and Vault data.]]
- [[https://github.com/jmgilman/vaultssh][jmgilman/vaultssh: A small CLI wrapper for authenticating with SSH keys from Hashicorp Vault]]
- [[https://github.com/hashicorp/vault-action][hashicorp/vault-action: A GitHub Action that simplifies using HashiCorp Vault™ secrets as build variables.]]
- [[https://github.com/kubevault/kubevault][kubevault/kubevault: KubeVault Documentation]]
- [[https://github.com/DeterminateSystems/nixos-vault-service][DeterminateSystems/nixos-vault-service]]
- [[https://habr.com/ru/company/nixys/blog/578870/][Взаимное автоматическое распечатывание двух Vault кластеров в Kubernetes / Хабр]]

* Jenkins
- [[https://www.admin-magazine.com/Archive/2019/51/Jenkins-Configuration-as-Code/(offset)/3][JCasC » ADMIN Magazine]]
- [[https://groups.google.com/g/vault-tool/c/ZTEb5ziRsng/m/du69_G7UAwAJ][Reniew token with Jenkins]]

* Tools
- [[https://github.com/banzaicloud/bank-vaults][banzaicloud/bank-vaults: A Vault swiss-army knife: a K8s operator, Go client with automatic token renewal, automatic configuration, multiple unseal options and more. A CLI tool to init, unseal and configure Vault (auth methods, secret engines). Direct secret injection into Pods.]]
