:PROPERTIES:
:ID:       9bd9dd4b-0d7b-45b0-b9e3-5a9d54f8417e
:END:
- snapshot
  : lvcreate --size 4G --snapshot --name magnolia--vg-root-01 /dev/mapper/magnolia--vg-root

- snapshot thin (do not specify size the creating a thin snapshot)
  : lvcreate --snapshot --name magnolia--vg-root-01 /dev/mapper/magnolia--vg-root

- [[https://www.man7.org/linux/man-pages/man7/lvmvdo.7.html][lvmvdo(7) - Linux manual page]]

- increase size of logical volume
  : lvextend -L+10G /dev/lvm1/web99

- fullreport
  : lvm fullreport, see lvm-fullreport(8)

- output in json, see lvmreport(7)
  : lvs -o lv_name,lv_size --reportformat json

- [[https://storytime.ivysaur.me/posts/why-not-zfs/][Why not ZFS]]

root@guixsd ~ [env]# pvcreate /dev/sdd5 
File descriptor 5 (/gnu/store/2rlcdsb7p3njs7wbh2nanyl7j14gwj1w-guix-command) leaked on pvcreate invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
File descriptor 14 (socket:[112552]) leaked on pvcreate invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
  Physical volume "/dev/sdd5" successfully created.

root@guixsd ~ [env]# vgcreate lvm1 /dev/sdd5
File descriptor 5 (/gnu/store/2rlcdsb7p3njs7wbh2nanyl7j14gwj1w-guix-command) leaked on vgcreate invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
File descriptor 14 (socket:[112552]) leaked on vgcreate invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
  Volume group "lvm1" successfully created

root@guixsd ~ [env]# vgchange -a y lvm1
File descriptor 5 (/gnu/store/2rlcdsb7p3njs7wbh2nanyl7j14gwj1w-guix-command) leaked on vgchange invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
File descriptor 14 (socket:[112552]) leaked on vgchange invocation. Parent PID 8206: /gnu/store/d99ykvj3axzzidygsmdm
  0 logical volume(s) in volume group "lvm1" now active

root@guixsd ~ [env]# virsh pool-define-as lvm1 logical --source-name lvm1 --target /dev/sdd5 
Pool lvm1 defined

root@guixsd ~ [env]# virsh pool-start lvm1
Pool lvm1 started


[root@localhost ~]# pvcreate /dev/vdb1
  Physical volume "/dev/vdb1" successfully created.
[root@localhost ~]# vgcreate vg0 /dev/vdb1
  Volume group "vg0" successfully created
[root@localhost ~]# lvcreate -l 100%FREE -Zn --type thin-pool --thinpool pool0 vg0
  Thin pool volume with chunk size 64.00 KiB can address at most <15.88 TiB of data.
  Logical volume "pool0" created.
[root@localhost ~]# lvcreate -T vg0/pool0 -V 9 -n volume0
  Rounding up size to full physical extent 12.00 MiB
  Logical volume "volume0" created.

** Create a thin pool

: modprobe dm-thin-pool

#+begin_example
  root@guixsd ~# lvcreate -l 100%FREE --thinpool thinpool2 vg0
    Thin pool volume with chunk size 1.00 MiB can address at most 253.00 TiB of data.
    WARNING: Pool zeroing and 1.00 MiB large chunk size slows down thin provisioning.
    WARNING: Consider disabling zeroing (-Zn) or using smaller chunk size (<512.00 KiB).
    Logical volume "thinpool2" created.
#+end_example

#+begin_example
  root@guixsd ~# lvs
    LV                            VG   Attr       LSize   Pool Origin Data%  Meta%  Move Log Cpy%Sync Convert
    almalinux                     lvm1 -wi-a-----  30.00g
    centos                        lvm1 -wi-a-----  20.00g
    centos7                       lvm1 -wi-a-----  32.00g
    debian1                       lvm1 -wi-a-----  16.00g
    debian2                       lvm1 -wi-a-----  16.00g
    guix                          lvm1 -wi-a-----  64.00g
    guix-test                     lvm1 -wi-a-----  40.50g
    nginx99                       lvm1 -wi-a-----  34.00g
    nixos                         lvm1 -wi-a-----  20.00g
    nixos-test                    lvm1 -wi-a-----  20.00g
    qubeos                        lvm1 owi---s---  64.00g
    qubeos-snap1                  lvm1 swi---s---  32.00g      qubeos
    qubes                         lvm1 -wi-a-----  64.00g
    test                          lvm1 -wi-a-----  10.00g
    ubuntu                        lvm1 -wi-a-----  64.00g
    web99                         lvm1 -wi-a-----  80.00g
    whonix-gateway-direct         lvm1 -wi-a-----   8.00g
    whonix-workstation-qbittorent lvm1 -wi-a-----  10.00g
    win10                         lvm1 -wi-a-----  40.00g
    ntfs-games                    lvm2 -wi-a----- 520.00g
    thinpool2                     lvm2 twi-a-tz--  <1.22t             0.00   10.43
    ubuntu22.04                   lvm2 -wi-a-----  20.00g
#+end_example

#+begin_example
  root@guixsd ~# lvcreate -V 521G --thin -n ntfsgames lvm2/thinpool2
    /usr/sbin/thin_check: execvp failed: No such file or directory
    WARNING: Check is skipped, please install recommended missing binary /usr/sbin/thin_check!
    /usr/sbin/thin_check: execvp failed: No such file or directory
    WARNING: Check is skipped, please install recommended missing binary /usr/sbin/thin_check!
    Logical volume "ntfsgames" created.
#+end_example

lvcreate -l 100%FREE --thinpool thinpool0 vg0
lvcreate -V 16G --thin -n thinguix vg0/thinpool0

#+begin_example
  root@guixsd ~# lvs
    LV                            VG   Attr       LSize   Pool      Origin Data%  Meta%  Move Log Cpy%Sync Convert
    almalinux                     lvm1 -wi-a-----  30.00g
    centos                        lvm1 -wi-a-----  20.00g
    centos7                       lvm1 -wi-a-----  32.00g
    debian1                       lvm1 -wi-a-----  16.00g
    debian2                       lvm1 -wi-a-----  16.00g
    guix                          lvm1 -wi-a-----  64.00g
    guix-test                     lvm1 -wi-a-----  40.50g
    nginx99                       lvm1 -wi-a-----  34.00g
    nixos                         lvm1 -wi-a-----  20.00g
    nixos-test                    lvm1 -wi-a-----  20.00g
    qubeos                        lvm1 owi---s---  64.00g
    qubeos-snap1                  lvm1 swi---s---  32.00g           qubeos
    qubes                         lvm1 -wi-a-----  64.00g
    test                          lvm1 -wi-a-----  10.00g
    ubuntu                        lvm1 -wi-a-----  64.00g
    web99                         lvm1 -wi-a-----  80.00g
    whonix-gateway-direct         lvm1 -wi-a-----   8.00g
    whonix-workstation-qbittorent lvm1 -wi-a-----  10.00g
    win10                         lvm1 -wi-a-----  40.00g
    ntfs-games                    lvm2 -wi-a----- 520.00g
    ntfsgames                     lvm2 Vwi-a-tz-- 521.00g thinpool2        0.00
    thinpool2                     lvm2 twi-aotz--  <1.22t                  0.00   10.43
    ubuntu22.04                   lvm2 -wi-a-----  20.00g
#+end_example

#+begin_example
  root@guixsd ~# dd if=/dev/lvm2/ntfs-games of=/dev/lvm2/ntfsgames bs=1024K status=progress
  557988184064 bytes (558 GB, 520 GiB) copied, 1577 s, 354 MB/s
  532480+0 records in
  532480+0 records out
  558345748480 bytes (558 GB, 520 GiB) copied, 1585.59 s, 352 MB/s
#+end_example

#+begin_example
  root@guixsd ~ [env]# lvextend -L+50G /dev/lvm2/ntfsgames
  File descriptor 5 (/gnu/store/pzpj58wi3m4y2g3qsd5xzpj7ncj28ym6-guix-command) leaked on lvextend invocation. Parent PID 12037: /gnu/store/d99ykvj3axzzidygsmdm
    Size of logical volume lvm2/ntfsgames changed from 521.00 GiB (133376 extents) to 571.00 GiB (146176 extents).
    Logical volume lvm2/ntfsgames successfully resized.
#+end_example

#+begin_example
  root@guixsd ~ [env]# lvs
  File descriptor 5 (/gnu/store/pzpj58wi3m4y2g3qsd5xzpj7ncj28ym6-guix-command) leaked on lvs invocation. Parent PID 12037: /gnu/store/d99ykvj3axzzidygsmdm
    LV                            VG   Attr       LSize   Pool      Origin Data%  Meta%  Move Log Cpy%Sync Convert
    almalinux                     lvm1 -wi-a-----  30.00g
    centos                        lvm1 -wi-a-----  20.00g
    centos7                       lvm1 -wi-a-----  32.00g
    debian1                       lvm1 -wi-a-----  16.00g
    debian2                       lvm1 -wi-a-----  16.00g
    guix                          lvm1 -wi-a-----  64.00g
    guix-test                     lvm1 -wi-a-----  40.50g
    nginx99                       lvm1 -wi-a-----  34.00g
    nixos                         lvm1 -wi-a-----  20.00g
    nixos-test                    lvm1 -wi-a-----  20.00g
    qubeos                        lvm1 owi---s---  64.00g
    qubeos-snap1                  lvm1 swi---s---  32.00g           qubeos
    qubes                         lvm1 -wi-a-----  64.00g
    test                          lvm1 -wi-a-----  10.00g
    ubuntu                        lvm1 -wi-a-----  64.00g
    web99                         lvm1 -wi-a-----  80.00g
    whonix-gateway-direct         lvm1 -wi-a-----   8.00g
    whonix-workstation-qbittorent lvm1 -wi-a-----  10.00g
    win10                         lvm1 -wi-a-----  40.00g
    ntfs-games                    lvm2 -wi-a----- 520.00g
    ntfsgames                     lvm2 Vwi-a-tz-- 571.00g thinpool2        91.07
    thinpool2                     lvm2 twi-aotz--  <1.22t                  41.66  20.97
    ubuntu22.04                   lvm2 -wi-a-----  20.00g
#+end_example

* Learning
- [[https://www.redhat.com/sysadmin/lvm-vs-partitioning][Logical Volume Manager (LVM) versus standard partitioning in Linux | Enable Sysadmin]]
- [[https://sleeplessbeastie.eu/2022/01/07/how-to-use-lvm-thin-provisioning/][How to use LVM thin provisioning – sleeplessbeastie's notes]]
- [[https://www.linuxsysadmins.com/create-thinly-provisioned-logical-volume/][Create a Thinly Provisioned Logical Volume on Linux]]
- [[https://unix.stackexchange.com/questions/623346/lvm-type-raid1-thinpool-is-it-possible][software raid - LVM type raid1 & thinpool is it possible? - Unix & Linux Stack Exchange]]
- [[https://habr.com/ru/post/592855/][LVM Thinpool Restore / Хабр]]

- LVMTHIN(7)

**  Extend thin LVM Metadata Size
*** Question

I was wondering how I can extend Metadata size in a lvm thin provisioning (on latest Kernel / LVM2).

#+begin_example
  [root@srv ~]# lvs -a
  LV                VG        Attr       LSize   Pool Origin Data%  Meta%  
  lv1               volgroup1 twi-aotz-- 125.00g             25.80   23.32
  [lv1_tdata]       volgroup1 Twi-ao---- 125.00g
  [lv1_tmeta]       volgroup1 ewi-ao----  96.00m
  lvol0             volgroup1 -wi-a-----  96.00m
  [lvol1_pmspare]   volgroup1 ewi-------  96.00m
#+end_example

I have few questions:

    In above 'lvs' command 23.32% is Meta%, this means 23.32% of 96M is used
    for META (or of total 125G) ?  lvol1_pmspare is a spare copy of
    meta. Should i need to extend lvol1_pmspare separately to extend
    lv1_tmeta.  Any performance impact by changing thin_pool_chunk_size or
    setting poolmetadatasize to higher value.  How to identify ideal metadata
    size.

Can someone please share your insight and help me on how to extend metadata size.

*** Answer A
You can use =lvs -a= to view details of metadata and pmspare as in question.

To extend metadata:

: lvextend -L+128M volgroup1/lv1_tmeta

You will see lvol1_pmspare (metadata spare) remains original size even after
above command is successful. =lvconvert --repair= process will re-create the
spare metadata LV. ( Or you can also remove lvol1_pmspare and re-create using
=lvconvert --repair=)

Metadata size can be somewhere between 2M to 16G. An ideal value always
depends on the total volume and type of operations.

*** Answer B

This will do the trick without any --repair.

: lvextend --poolmetadatasize +2G vg0/lv0

* Backup
- [[https://github.com/tasket/wyng-backup][tasket/wyng-backup: Fast Time Machine-like backups for logical volumes]]
- [[https://github.com/sebastian13/lvm-restic-backup][sebastian13/lvm-restic-backup]]

* Cheatsheet

- create logical volume
  : lvcreate -L 100G lvm1 -n whonix-gateway

- Fix "LV Status" is "NOT available"
  : vgchange -a y VOLNAME

- Increase psycial volume size
  : pvresize /dev/vda1

- Increase logical volume size
  : lvresize -l 100%FREE /dev/mapper/vg0-guix

- Increase logical volume size by 16 GB
  : lvresize -L+16G /dev/VOLUME_GROUP/VOLUME_NAME

* Snapshots

root@guixsd ~ [env]# modprobe dm-snapshot
root@guixsd ~ [env]# lvcreate -L 32G -n qubeos-snap1 -s /dev/lvm1/qubeos
File descriptor 5 (/gnu/store/9dwykxc9sdml1fn9d8hgpsfifb9fv684-guix-command) leaked on lvcreate invocation. Parent PID 30051: /gnu/store/d99ykvj3axzzidygsmdm
  Logical volume "qubeos-snap1" created.

- revert changes
  : lvconvert --merge /dev/lvm1/qubeos-snap1

- delete snapshot and save changes
  : lvremove /dev/lvm1/qubeos-snap1

** MariaDB

- [[https://www.oreilly.com/library/view/mariadb-high-performance/9781783981601/ch11s03.html][LVM - MariaDB High Performance Book]]

To make a usable MariaDB datadir snapshot, you first need to lock your tables:
: MariaDB [(none)]> flush tables with read lock;

Now we're sure there will be no changes on our instance. Let's create the
snapshot on the system:
: lvcreate --snapshot -n snap_mariadb ...

* Mount

#+begin_example
  root@guixsd ~ [env]# parted /dev/lvm1/debian1 
  GNU Parted 3.4
  Using /dev/dm-11
  Welcome to GNU Parted! Type 'help' to view a list of commands.
  (parted) unit                                                             
  Unit?  [compact]? B                                                       
  (parted) print                                                            
  Model: Linux device-mapper (linear) (dm)
  Disk /dev/dm-11: 17179869184B
  Sector size (logical/physical): 512B/4096B
  Partition Table: gpt
  Disk Flags: 

  Number  Start       End           Size          File system  Name  Flags
  14      1048576B    4194303B      3145728B                         bios_grub
  15      4194304B    134217727B    130023424B    fat16              boot, esp
   1      134217728B  17179852287B  17045634560B  ext4
#+end_example

#+begin_example
  mount -o loop,offset=134217728 /dev/lvm1/debian1 /mnt/debian1
#+end_example

lvchange -ay -v lvm2/thinpool2
lvchange -ay -v lvm2/ntfsgames

#+begin_example
  dmsetup ls

  lvm1-centos	(253:2)
  lvm1-centos7	(253:7)
  lvm1-debian1	(253:10)
  ...
#+end_example

[[https://superuser.com/questions/131519/what-is-this-dm-0-device][linux - What is this dm-0 device? - Super User]]
#+begin_example
  sudo lvdisplay|awk  '/LV Name/{n=$3} /Block device/{d=$3; sub(".*:","dm-",d); print d,n;}'

  dm-1 nixos
  dm-2 centos
  dm-3 web99
  ...
#+end_example

#+begin_example
  lsblk --output NAME,KNAME,TYPE,SIZE,MOUNTPOINT
  NAME                                     KNAME   TYPE    SIZE MOUNTPOINT
  sda                                      sda     disk  931.5G
  ...
  └─sdd5                                   sdd5    part  927.5G
    ├─lvm1-nixos                           dm-1    lvm      20G
  ...
#+end_example

#+begin_example
  iostat -x -d 1
#+end_example

* ChatGPT

** Why `lvcreate` sometimes does not add new logical volume as device to `/dev` directory?

lvcreate creates a new logical volume, but it does not automatically create a device node for it in the /dev directory. This is because the device node is typically created by the udev system, which detects when new storage devices are added or removed from the system, and creates the corresponding device nodes in the /dev directory.

If the device node for the new logical volume is not immediately visible in the /dev directory, it is possible that udev has not yet had a chance to create the device node. This can sometimes occur if udev is busy processing other events or if there is a delay in detecting the new device.

To force udev to create the device node immediately, you can run the following command:

sql

sudo udevadm trigger

This will force udev to re-evaluate all pending events and create any missing device nodes. Once the command completes, the device node for the new logical volume should be visible in the /dev directory.

** How to list all pending events?

To list all pending events in the udev system, you can run the following command:

scss

sudo udevadm monitor --property --subsystem-match=block

This command will monitor udev events related to the block subsystem (i.e., storage devices), and display detailed information about each event, including the name and properties of the affected device.

If you want to see a list of all pending events without monitoring for new events, you can run the following command instead:

css

sudo udevadm trigger --dry-run --verbose

This command will simulate the processing of all pending events and display detailed information about each event that would be processed by udev. Note that this command does not actually modify the system or create any device nodes. It is intended only for diagnostic purposes.
