* Cheat sheet

- Remote docker host
  : export DOCKER_HOST=ssh://sammy@your_server_ip

- Compose
  : docker-compose --project-name pxe --file pxe.yml up -d --force

- List running docker containers with image hashes
  : docker inspect --format='{{.Id}} {{.Name}} {{.Image}}' $(docker ps -aq)

- exit from interactive shell without killing container
  : c-p-q

- xorg
  #+BEGIN_SRC sh
    docker run -it \
           -w /opt/tome4 \
           -v /tmp/.X11-unix:/tmp/.X11-unix \
           -v /opt/tome4/rootfs/opt/tome4:/opt/tome4 \
           -v /opt/tome4/rootfs/home/user:/home/user \
           -v /home/oleg/.t-engine:/root/.t-engine \
           -v /etc/localtime:/etc/localtime:ro \
           -v "/srv/lib/Tales of Maj'Eyal - GOG Linux":/install \
           -e DISPLAY \
           --rm -u1000: \
           --network=host \
           --name tome4 \
           --hostname tome4 \
           --device /dev/snd \
           --device /dev/input \
           --device /dev/dri \
           --env PULSE_SERVER=unix:/tmp/pulseaudio.socket \
           --env PULSE_COOKIE=/tmp/pulseaudio.cookie \
           --volume /tmp/pulseaudio.socket:/tmp/pulseaudio.socket \
           --volume /tmp/pulseaudio.client.conf:/etc/pulse/client.conf \
           tome4:1.6.0 ./start.sh
  #+END_SRC

* Awesome

- https://github.com/hadolint/hadolint

* Katacoda

** What is Swarm Mode
   
In this scenario, you will learn how to initialise a Docker Swarm Mode cluster and deploy networked containers using the built-in Docker Orchestration. The environment has been configured with two Docker hosts.

In 1.12, Docker introduced Swarm Mode. Swarm Mode enables the ability to deploy containers across multiple Docker hosts, using overlay networks for service discovery with a built-in load balancer for scaling the services.

Swarm Mode is managed as part of the Docker CLI, making it a seamless experience to the Docker ecosystem.

Key Concepts
Docker Swarm Mode introduces three new concepts which we'll explore in this scenario.

Node: A Node is an instance of the Docker Engine connected to the Swarm. Nodes are either managers or workers. Managers schedules which containers to run where. Workers execute the tasks. By default, Managers are also workers.

Services: A service is a high-level concept relating to a collection of tasks to be executed by workers. An example of a service is an HTTP Server running as a Docker Container on three nodes.

Load Balancing: Docker includes a load balancer to process requests across all containers in the service.

This scenario will help you learn how to deploy these new concepts.

** Step 1 - Initialise Swarm Mode
Turn single host Docker host into a Multi-host Docker Swarm Mode. Becomes Manager By default, Docker works as an isolated single-node. All containers are only deployed onto the engine. Swarm Mode turns it into a multi-host cluster-aware engine.

The first node to initialise the Swarm Mode becomes the manager. As new nodes join the cluster, they can adjust their roles between managers or workers. You should run 3-5 managers in a production environment to ensure high availability.

Task: Create Swarm Mode Cluster
Swarm Mode is built into the Docker CLI. You can find an overview the possibility commands via docker swarm --help

The most important one is how to initialise Swarm Mode. Initialisation is done via init.

docker swarm init

After running the command, the Docker Engine knows how to work with a cluster and becomes the manager. The results of an initialisation is a token used to add additional nodes in a secure fashion. Keep this token safe and secure for future use when scaling your cluster.

In the next step, we will add more nodes and deploy containers across these hosts.

** Step 2 - Join Cluster
With Swarm Mode enabled, it is possible to add additional nodes and issues commands across all of them. If nodes happen to disappear, for example, because of a crash, the containers which were running on those hosts will be automatically rescheduled onto other available nodes. The rescheduling ensures you do not lose capacity and provides high-availability.

On each additional node, you wish to add to the cluster, use the Docker CLI to join the existing group. Joining is done by pointing the other host to a current manager of the cluster. In this case, the first host.

Docker now uses an additional port, 2377, for managing the Swarm. The port should be blocked from public access and only accessed by trusted users and nodes. We recommend using VPNs or private networks to secure access.

Task
The first task is to obtain the token required to add a worker to the cluster. For demonstration purposes, we'll ask the manager what the token is via swarm join-token. In production, this token should be stored securely and only accessible by trusted individuals.

token=$(ssh -o StrictHostKeyChecking=no 172.17.0.49 "docker swarm join-token -q worker") && echo $token

On the second host, join the cluster by requesting access via the manager. The token is provided as an additional parameter.

docker swarm join 172.17.0.49:2377 --token $token

By default, the manager will automatically accept new nodes being added to the cluster. You can view all nodes in the cluster using docker node ls

** Step 3 - Create Overlay Network
Swarm Mode also introduces an improved networking model. In previous versions, Docker required the use of an external key-value store, such as Consul, to ensure consistency across the network. The need for consensus and KV has now been incorporated internally into Docker and no longer depends on external services.

The improved networking approach follows the same syntax as previously. The overlay network is used to enable containers on different hosts to communicate. Under the covers, this is a Virtual Extensible LAN (VXLAN), designed for large scale cloud based deployments.

Task
The following command will create a new overlay network called skynet. All containers registered to this network can communicate with each other, regardless of which node they are deployed onto.

docker network create -d overlay skynet

** Step 4 - Deploy Service
By default, Docker uses a spread replication model for deciding which containers should run on which hosts. The spread approach ensures that containers are deployed across the cluster evenly. This means that if one of the nodes is removed from the cluster, the instances would be already running on the other nodes. The workload on the removed node would be rescheduled across the remaining available nodes.

A new concept of Services is used to run containers across the cluster. This is a higher-level concept than containers. A service allows you to define how applications should be deployed at scale. By updating the service, Docker updates the container required in a managed way.

Task
In this case, we are deploying the Docker Image katacoda/docker-http-server. We are defining a friendly name of a service called http and that it should be attached to the newly created skynet network.

For ensuring replication and availability, we are running two instances, of replicas, of the container across our cluster.

Finally, we load balance these two containers together on port 80. Sending an HTTP request to any of the nodes in the cluster will process the request by one of the containers within the cluster. The node which accepted the request might not be the node where the container responds. Instead, Docker load-balances requests across all available containers.

docker service create --name http --network skynet --replicas 2 -p 80:80 katacoda/docker-http-server

You can view the services running on the cluster using the CLI command docker service ls

As containers are started you will see them using the ps command. You should see one instance of the container on each host.

List containers on the first host - docker ps

List containers on the second host - docker ps

If we issue an HTTP request to the public port, it will be processed by the two containers curl host01.
