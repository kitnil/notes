:PROPERTIES:
:ID:       e430d654-a7b0-4625-b4be-56d697c0d142
:END:

* Learning

- [[https://habr.com/ru/company/southbridge/blog/510822/][–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Kubernetes: EFK –ø—Ä–æ—Ç–∏–≤ PLG / –•–∞–±—Ä]]

** Documentation

- [[https://www.elastic.co/guide/en/elasticsearch/reference/6.6/index.html][Elasticsearch Guide [6.6] | Elastic]]

** [[https://logz.io/blog/elasticsearch-cheat-sheet/][Elasticsearch Cheat Sheet in Times of Trouble]]

If you have worked with Elasticsearch (whether as part of the ELK Stack or not), I‚Äôm sure you know how awesome of a product it is. But the problem is that it can go from awesome to frustrating in less than a minute. Really, really frustrating.

That‚Äôs why we at log analytics platform Logz.io have compiled a cheat sheet of API calls to solve the problems that we have frequently encountered among our customers. We‚Äôre sure that they‚Äôre not the only ones!

Instead of going through Elasticsearch‚Äôs documentation yet another time or trying to find the solutions in random Stack Overflow answers, just save this in your favorites and visit in a time of need.
What is a time of need? Oh, you‚Äôll know it when it comes.
A brief introduction to Elasticsearch APIs

Elasticsearch has an extensive set of APIs that you can query or change at runtime. Each API call has a context, which is usually ‚Äúcluster,‚Äù ‚Äúnode,‚Äù or ‚Äúindex.‚Äù That means that some APIs change things cluster-wide, some are only for a specific node, and some are for a specific index.
When changing cluster settings, you have two options:

    Transient ‚Äì Changes that will not persist after a full cluster restart
    Persistent ‚Äì Changes that will be saved after a full cluster restart

Most of the changes below will be transient. If you want them to be persistent, change them in your Elasticsearch configuration (and make them transient in the meantime).
More on the subject:

    Use Logz.io to Instrument Kubernetes with OpenTelemetry & Helm
    Introducing Scheduled Reporting
    Hafnium Hacks Microsoft Exchange: Who‚Äôs at Risk?

Important note: Transient changes will be persistent when a node restarts or a new node joins a cluster. The master node will sync the changes for you automatically.
Another important note: Transient changes have precedence over persistent changes, which have precedence over the configuration file. Just keep that in mind.
Whenever you change transient settings, make sure that you revert them back to your prior configurations. Some changes can exhaust clusters and should be used only to help with recoveries. The following cheat sheet includes a number of Elasticsearch curl commands.

Elasticsearch Indices
List All Indices:

curl -X GET ‚Äòhttp://localhost:9200/_cat/indices?v

or

curl -v "localhost:9200/_cat/indices"

#You can also do this in Kibana Console by querying GET _cat/indices.
Delete an Elasticsearch Index

curl -X DELETE 'http://localhost:9200/examples'

Back up an Elasticsearch Index

curl -XPOST --header 'Content-Type: application/json' http://localhost:9200/_reindex -d '{
  "source": {
    "index1": "someexamples"
  },
  "dest": {
    "index2": "someexamples_copy"
  }
}'

List All Docs in an Index:

curl -X GET 'http://localhost:9200/elasticsearch_query_examples/_search'

List All Data

curl -XPUT --header 'Content-Type: application/json' http://localhost:9200/elasticsearch_query_examples/_doc/1 -d '{
   "value1" : "value2"
}'

Elasticsearch Queries

There are a few different basic commands for querying Elasticsearch. For more info on this, check out our rundown of Elasticsearch queries and the Elasticsearch query API.
Query with URL Parameters

curl -X GET http://localhost:9200/elasticsearch_query_examples/_search?q=hypocrite_senator

Query with Elasticsearch Query DSL

curl -XGET --header 'Content-Type: application/json' http://localhost:9200/examples/_search -d '{
      "query" : {
        "match" : { "hypocrite_senator": "graham-lindsey" }
    }
}'

By Date

curl GET filebeat-7.10.0-2020.11.03-000001/_search
 {
    "query": {
        "range" : {
            "timestamp": {
              "event.created": {
                  "time_zone": "+02:00"
                  "gte" : "now-15d/d"
                  "lt" : ‚Äúnow‚Äù 
              }
            }
        }
}
}

Elasticsearch Clusters
Move shards from one node to another

When to do it: When too many hot shards reside in one data node and you want to spread them out manually. Elasticsearch does not take these things into consideration when placing shards across the cluster, so sometimes it is necessary to move them manually.
The cURL command:

curl -XPOST 'http://localhost:9200/_cluster/reroute' -d '{
"commands" : [
{
"move" :
{
"index" : "indexname", "shard" : 1,
"from_node" : "nodename", "to_node" : "nodename"
}
}
]
}';echo

Force the allocation of an unassigned shard with a reason

When to do it: Sometimes you have unassigned shards in a cluster, but you just cannot figure out why. It can have plenty of causes such as lack of space or shard awareness. This will output a lot of verbose data. If you look at the end of the output, you will see the reason for the non-allocation. (Note: The ‚Äú?explain‚Äù part can be also applied to the previous curl to get a reason if you cannot move a shard around.)
The cURL command:

curl -XPOST 'http://localhost:9200/_cluster/reroute?explain' -d '{
"commands" : [ {
"allocate" : {
"index" : "indexname", "shard" : 0, "node" : "nodename"
}
} ]
}';echo

Remove nodes from clusters gracefully

When to do it: When you want to decommission a node or perform any type of maintenance without the cluster turning yellow or red (depending on your replicas settings). Note: If you drain a node and want to return it to the cluster afterward, you need to call that endpoint again with the IP field blank.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"cluster.routing.allocation.exclude._ip" : "1.2.3.4"
}
}';echo

Force a synced flush

When to do it: Before you restart a node that you are not gracefully removing from the cluster. This will place a sync ID on all indices, and as long as you are not writing to them, the recovery time of those shards will be significantly faster.
The cURL command:

curl -XPOST 'localhost:9200/_flush/synced'

Change the number of moving shards to balance the cluster

When to do it: Setting the cURL command (see below) to 0 will be useful if you have a planned maintenance and do not want the cluster to start to move shards under your feet. Setting a higher value will help to rebalance the cluster when a new node joins it.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"cluster.routing.allocation.cluster_concurrent_rebalance" : 2
}
}';echo

Change the number of shards being recovered simultaneously per node

When to do it: If a node has been disconnected from the cluster, all of its shards will be unassigned. After a certain delay, the shards will be allocated somewhere else. The number of concurrent shards per node that will be recovered is determined by that setting.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"cluster.routing.allocation.node_concurrent_recoveries" : 6
}
}';echo

Change the recovery speed

When to do it: To avoid overloading the cluster, Elasticsearch limits the speed that is allocated to recovery. You can carefully change that setting to make it recover more quickly.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"indices.recovery.max_bytes_per_sec" : "80mb"
}
}';echo

Change the number of concurrent streams for a recovery on a single node

When to do it: If a node has failed and you want to speed up recovery, you can increase this setting. Make sure to monitor the cluster so that you will not end uploading it too much.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"indices.recovery.concurrent_streams" : 6
}
}';echo

Change the size of the search queue

When to do it: If your cluster is loaded and takes too much time to answer search queries, you can carefully increase that setting so that you will not drop searches. (If you see an increase in the ‚Äúrejected‚Äù metric for any queue, this recommendation is applicable.)
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"transient" :{
"threadpool.search.queue_size" : 2000
}
}';echo

Clear the cache on a node

When to do it: If a node reaches a high JVM value, you can call that API as an immediate action on a node level to make Elasticsearch drop caches. It will hurt performance, but it can save you from OOM (Out Of Memory).
The cURL command:

curl -XPOST 'http://localhost:9200/_cache/clear'

Adjust the circuit breakers

When to do it: To avoid not getting to OOM in Elasticsearch, you can tweak the settings on the circuit breakers. This will limit the search memory and drop all searches that are estimated to consume more memory than that desired level. You can read more about that here. Note: This is a really delicate setting that you need to calibrate carefully.
The cURL command:

curl -XPUT localhost:9200/_cluster/settings -d '{
"persistent" : {
"indices.breaker.total.limit" : "40%"
}
}'; echo

Showing Cluster Health

curl --user $pwd  -H 'Content-Type: application/json' -XGET https://1234567876543219876567890.eu-central-1.aws.cloud.es.io:1234/_cluster/health?pretty

You can get a peek at your Elasticsearch cluster‚Äôs health by calling the Health API. Get back the status color for shard levels and index levels (green, all allocated; yellow, primary allocated by not replicas; red, specific shard is unallocated). Index level is evaluated by the worst shard; cluster status is then evaluated by worst index.
Easy Elasticsearch

** [[https://sematext.com/blog/elastic-search-data-storage-is-not-spreading-equally/][What To Do When Elasticsearch Data Is Not Spreading Equally Between Nodes]]

Table of Contents

    Prerequisite: Check for Ongoing Rebalancing
    Elasticsearch Imbalanced Data Spread: Causes & Fixes
    Recent node failure/join to cluster
    Misconfigured cluster settings
    Your One Stop Shop for Elasticsearch
    Hotspot nodes
    Routing field/key without enough diversity
    How to prevent Elasticsearch data storage imbalances
    Does your cluster math hold?
    Monitoring
    Avoid Premature Optimizations
    Summary

Elasticsearch (ES) is a powerful tool offering multiple search, content, and analytics capabilities. You can extend its capacity and relatively quickly horizontally scale the cluster by adding more nodes. When data is indexed in some Elasticsearch index, the index is not typically placed in one node but is spread across different nodes such that each node contains a ‚Äúshard‚Äù of the index data. The shard (called primary shard) is replicated across the cluster into several replicas.

A cluster is considered balanced when it has an equal number of shards on each data node without having an excess concentration of shards on any node. Unfortunately, you will sometimes run into cases where the cluster balance is suboptimal.

This article will review some of the cases that can cause the problem of data spreading unevenly across the cluster and how you can solve them.

In case you‚Äôre looking for some direct help, keep in mind that Sematext provides a full range of services for Elasticsearch.
Prerequisite: Check for Ongoing Rebalancing

Before we have any assumptions about the data spread, we need to check for an ongoing rebalance that might be taking place. Recovery is a process where a missing shard is reset to its respective node as a result of potentially a node going down or adding a new node. To check for active recoveries, run this query:

 GET _cat/recovery?active_only=true&v=true

If no rebalancing is going on and Elasticsearch data storage is not spreading equally, we‚Äôll need further troubleshooting. The sections below will explain the troubleshooting steps in detail.
Elasticsearch Imbalanced Data Spread: Causes & Fixes

The solution to Elasticsearch not equally spreading data storage amongst the nodes will depend on the cause. The table below details common causes and their solutions.
Causes for the uneven spread of data	Solutions
Recent node failure/join to cluster	Check the cluster recovery progress
Misconfigured cluster settings	Check the cluster settings as they can be pretty error prone such as the rules under cluster.routing.allocation.disk.*.
Hotspot nodes	Check the data allocation per node, consider setting a max shard per node count
Routing field/key without enough diversity	Manual shard routing can cause data to spread unequally; if you are using routing for tenant separation, for example, consider splitting the index to per tenant indices.

We‚Äôre also going to review ways to prevent data imbalances in Elasticsearch.
Prevention	Description
Monitoring and choosing correct sources	Checking for potential problems via monitoring IO, latency, and hardware inconsistencies
Avoid Premature Optimizations (default settings are the default for a reason)	Premature optimizations are one big source of evil
Recent node failure/join to cluster

When an Elasticsearch node goes down, an automatic recovery process will take place, followed by a rebalancing process, where the shard replicas are replicated across the remaining nodes of the cluster to maintain the replication factor. Rebalancing moves shards between the nodes in the cluster to improve its balance.

You can check for potential cluster incidents using your preferred monitoring tool like Sematext or Kibana and lookout for outliers in your cluster nodes or in your resource usage. If you don‚Äôt have a monitoring tool set up, you can always check for the cluster health to see if there are any unallocated/initializing shards via this query:

GET /_cluster/health

You can also check for ongoing rebalance as we demonstrated before with the _cat/recovery query. If none of these checks reveal a cause for the imbalance, the next step is to check your cluster‚Äôs settings for misconfigurations.
Misconfigured cluster settings

While Elasticsearch will always try to maintain the most balanced possible cluster, it will always be within the shard allocation rules you have set. Data storage imbalances can occur due to customized rules and settings.

Rebalancing considers shard allocation rules such as:

    Cluster-level & Index-Level shard allocation filtering
    You can use cluster-level shard allocation filters to control where Elasticsearch allocates shards i.e. you can use cluster.routing.allocation rules to allocate data to nodes with a specific tag.
    Forced awareness
    Forced awareness is about defining the features that will be used to allocate data into different storage units. An example of them would be racks, data centers, etc.
    Elasticsearch, by default, assigns all of the missing replica shards to the remaining locations if you have a multi-zone cluster and one location fails. This action may cause your other locations to receive an abnormally high load. To prevent overloads at a given location and make Elasticsearch wait for the location to recover, you can use the setting cluster.routing.allocation.awareness.force, so no replicas are allocated until nodes are available in another location. This setting could cause you to have unassigned shards until all your zones are back up and rebalanced.
    Disk-based shard allocation settings
    This set of rules ensures that data is spread across the different nodes with hard disk taken into consideration.
    Some of the settings you‚Äôll have in this category:
    Cluster.routing.allocation.disk.threshold_enabled while this is enabled by default, it means that disk is always considered when
    Cluster.routing.allocation.disk.watermark.low has a default value of 85%, meaning that Elasticsearch will not allocate shards to nodes that have more than 85% disk used.
    These rules clearly indicate that if there are some outliers in the node‚Äôs disk (logs, OS, or other app-related disk content), it will clearly cause shards to spread unequally across the cluster. Also, keep in mind that shards can vary in size (because they belong to different indices or because there‚Äôs routing in the same index). If just some nodes hit disk thresholds, then shards will get allocated differently than you might expect.

You can check for defined settings with

GET /_cluster/settings

If you are using data tiers to separate your content (e.g., hot, cold, documents, etc.), then Elasticsearch automatically applies allocation filtering rules to place each shard within the appropriate tier. That means you don‚Äôt have to worry about the tiers as a whole since the balancing process works independently within each tier.

Your One Stop Shop for Elasticsearch
Learn More
Platform	Open Source Stack	Community Help	Monitoring ‚Äì Metrics, Logs. Health, Alerting SaaS	Training, Implementation & Maintenance	Production Support & Consulting
Elasticsearch	‚úì	‚úì			
Elasticsearch + Sematext	‚úì	‚úì	‚úì	‚úì	‚úì
Hotspot nodes

If too many shards from the same index exist in the same node, you have a hotspot node, and hotspot nodes are likely to have issues.

A way to detect a hot spot is to use the query:

GET _cat/nodes?h=node,ram.percent,cpu,load_1m,disk.used_percent&v

Should give you a response that looks like this:

ram.percent cpu load_1m disk.used_percent
        79   4    0.06      31.70
        75   2    0.03      31.24
        73   6    0.03      31.50

This query should help you to quickly spot any outliers between the nodes in your cluster, and keep in mind minor differences are always expected, but you should be able to have a timeseries graph of this data via some monitoring tool like Sematext Cloud for best visibility, because load will vary over time:

Another thing to keep an eye on is the shard count per node. You can check for that via

GET _cat/shards?h=index,shard,prirep,node&v

In the case of skew in shard spread, a quick solution to this problem is setting an explicit value for the number of shards to be allocated per node:

Index.routing.allocation.total_shards_per_node

from the update index settings API. However, you should keep in mind that setting this value, especially a value without an adequate safety margin, can cause some shards to remain unallocated since it‚Äôs a hard limit (this can happen in cases of node failure if the other nodes are out of resources).

You have set the max number of shards per node, but what if there is a hot shard? In this case, you‚Äôll have equally spread shard counts, but the content is denser in one compared to the other due to reasons like misusing routing fields.

You could also have a case of a hot index, which is one very common reason for data imbalance. Elasticsearch tries to balance shards equally, but it doesn‚Äôt rely on the size of shards or how much load they take. But if the number of shards doesn‚Äôt divide by the number of nodes, you‚Äôll likely have an imbalance.
Routing field/key without enough diversity

Setting a routing key for the indexed data can be a performance tweak. However, this tweak will depend heavily on your data and the good usage of this feature.

If you‚Äôre using this feature with a field like tenantId then keep in mind that you have to be aware of how big or small each tenant is since that will directly affect the spread of data.

Elasticsearch uses _id field as a routing field by default. Setting the routing field for an index to the wrong field where you have too many repeated values of some type can cause you to end up with uneven-sized shards.

You‚Äôll need to check your indexing requests and check your used field. That query looks like this:

PUT user-index/_doc/1?routing=company1
{
    "name": "john",
    "lastName": "doe",
}

If the routing key you used (company1 in our example) is too frequently related to other keys you used and there isn‚Äôt enough key diversity across your data, you‚Äôll run into some issues. The issues arise because data is routed to a specific shard based on this formula:

routing_factor = num_routing_shards / num_primary_shards
shard_num = (hash(_routing) % num_routing_shards) / routing_factor,

For example, if you have four shards and used in total four keys ‚Äúcompany1‚Äù,‚Äùcompany2‚Ä≥‚Ä¶, shard allocation will depend directly on the data spread across those keys. Therefore, if docs routed using ‚Äúcompany1‚Äù key are much more common than ‚Äúcompany2‚Äù you‚Äôll end up with very uneven shard allocation.

A way out of this problem is to be watchful about why you have this routing field and try to think about the following:

    Do you use this routing field in the first place in your queries? If not you can reindex your data without it.
    Do you have a few large (tenants pre the example) and the others are much smaller? Then you need to consider to take out larger tenants to their respective indices and keep the other ‚Äútenants‚Äù in the original index.

How to prevent Elasticsearch data storage imbalances

There are many steps you can take to help us avoid data inconsistent spread in Elasticsearch. However, two essential practices can reduce the frequency and scope of data imbalances: monitoring and proper configuration.
Does your cluster math hold?

An initial point to think of is making sure the number of shards per index is a multiplier of the number of nodes; this is a very common problem that is often overlooked. You can always validate your clus href=‚Äùhttps://gbaptista.github.io/elastic-calculator/‚Äù>this tool.
Monitoring

To maintain a healthy Elasticsearch data storage balance, you should monitor these categories of metrics at a minimum:

    IO and Latency: the first metrics to look out for to measure the load under which your cluster lies and be watchful if there are unexplained spikes.

    Memory: Elasticsearch runs on JVM therefore, the memory heap for Elasticsearch should maintain a moderately used heap memory to indicate the healthiness of the node. Here‚Äôs a view from Sematext Cloud:

    Network: Elasticsearch is often deployed in the cloud, so network quotas are a common bottleneck to keep an eye on.

    CPUs: Elasticsearch housekeeping jobs will always run in the background. If you do not have enough resources, those jobs (such as merging and refreshing) could fail to run, and you can end up with imbalanced shard sizes.

Once you see a problem with any relevant metrics, you can respond and address them before they create major issues.

For insights on relevant metrics, see our blog post on important Elasticsearch metrics to watch and alert on.
Avoid Premature Optimizations

Default Settings in Elasticsearch are already reasonable and, most of the time and don‚Äôt need to be changed unless you have a specific purpose ‚Äî like security hardening or performance optimization to address a specific use case ‚Äî err on the side of the default settings.

As we have explained above we can notice that there are many cases where, if you‚Äôre changing the default manner Elasticsearch works, whether it‚Äôs cluster settings or using routing keys. It is very important to be aware of the consequences of each change of the default values and not touch them unless necessary.
Summary

Cluster misconfiguration and suboptimal architecture are common reasons your Elasticsearch data spread imbalances can occur.

With the troubleshooting steps we‚Äôve covered in this article, such as keeping your default configurations as-is, setting the number of shards as a multiplier to the number of nodes, and checking your allocation filtering rules; you can be better prepared to address problems as they happen.

Additionally, by taking simple preventative measures, most importantly monitoring, along with keeping an open eye on metrics, you can reduce the risk of imbalances impacting your Elasticsearch implementation.

* Cheet sheet

- [[https://www.elastic.co/guide/en/elasticsearch/reference/current/xpack-ccr.html][Cross-cluster replication | Elasticsearch Guide [7.15] | Elastic]]
- [[https://github.com/wfxr/elastic-tunnel][wfxr/elastic-tunnel: Tools for downloading data from elasticsearch]]
- [[https://github.com/wfxr/estunnel][wfxr/estunnel: Tool for downloading data from elasticsearch cluster.]]

- [[https://github.com/cch123/elasticsql][cch123/elasticsql: convert sql to elasticsearch DSL in golang(go)]]

- [[https://github.com/lmangani/sentinl][lmangani/sentinl: Kibana Alert & Report App for Elasticsearch]]

- [[https://archivy.github.io/][Index - Archivy]]

- https://gist.github.com/ruanbekker/e8a09604b14f37e8d2f743a87b930f93

- [[https://github.com/outflanknl/RedELK/][outflanknl/RedELK: Red Team's SIEM - tool for Red Teams used for tracking and alarming about Blue Team activities as well as better usability in long term operations.]]

- [[https://github.com/shirosaidev/diskover][shirosaidev/diskover: File system crawler, disk space usage, file search engine and file system analytics powered by Elasticsearch]]

- [[https://github.com/maxyermayank/docker-compose-elasticsearch-kibana][maxyermayank/docker-compose-elasticsearch-kibana: Docker Compose for Elasticsearch and Kibana]]

- [[https://github.com/elastic/examples][elastic/examples: Home for Elasticsearch examples available to everyone. It's a great way to get started.]] 

- [[https://github.com/bitemyapp/bloodhound][bitemyapp / bloodhound Haskell Elasticsearch client and query DSL]]

- root@web15 /etc/filebeat # filebeat -e -d "publish"

- [[https://www.elastic.co/guide/en/elasticsearch/reference/6.8/array.html][Arrays | Elasticsearch Reference [6.8] | Elastic]]

- list hot threads
  : curl '127.0.0.1:9200/_nodes/hot_threads'
  : e.g.: xsdCCWz

- kill threads
  : for thread in $(curl '127.0.0.1:9200/_cat/tasks?detailed' | grep xsdCCWz | grep read | awk '{ print $2 }'); do curl -XPOST "127.0.0.1:9200/_tasks/$thread/_cancel"; done

- [[https://www.elastic.co/guide/en/elasticsearch/reference/6.8/indices-templates.html#indices-templates][Index Templates | Elasticsearch Reference [6.8] | Elastic]]

- Disable readonly for all indexes
  : curl -XPUT -H "Content-Type: application/json" http://localhost:9200/_all/_settings -d '{"index.blocks.read_only_allow_delete": null}'
  https://techoverflow.net/2019/04/17/how-to-fix-elasticsearch-forbidden-12-index-read-only-allow-delete-api/

- Disable readonly
  : curl -H 'Content-Type: application/json' -XPUT 'http://localhost:9200/filebeat-*/_settings' --data '{"index":{"blocks": {"read_only_allow_delete": "false"}}}'
  (could use ‚Äú*‚Äù instead of ‚Äúelastalert_status_status‚Äù)

- exclude rc-user
  : service:rc-user AND log_level:ERROR AND -log_message:"ftp"

- https://qbox.io/blog/indexing-emails-to-elasticsearch-logstash-imap

- [[https://github.com/opensearch-project/OpenSearch][opensearch-project/OpenSearch: Open source distributed and RESTful search engine.]]

- [[https://github.com/elastic/elasticsearch-dsl-py][elastic/elasticsearch-dsl-py: High level Python client for Elasticsearch]]

- [[https://youtu.be/HSXuGU6f0yo][Kibana Searches]]

- create filebeat index in opensearch-dashboards
  : kubectl -n opensearch exec pod/opensearch-dashboards-xxxxxxxxxx-xxxxx -- curl -u admin:PASSWORD -X POST 'http://opensearch-dashboards.opensearch:5601/api/saved_objects/index-pattern/filebeat-*' -H "osd-xsrf:true" -H "content-type:application/json" -d '{"attributes": {"title": "filebeat-*", "timeFieldName": "@timestamp"}}'

- setup filebeat templates for kibana
  : filebeat setup -e -strict.perms=false -E output.elasticsearch.hosts=[elasticsearch:9200] -E setup.kibana.host="http://172.17.0.1:5601" -E name=guixsd

- Create index
  : curl -XPUT localhost:9200/foo

- List indexes
  : curl 'localhost:9200/_cat/indices?v&pretty'

- List yellow indexes
  : curl 'es.intr:9200/_cat/indices?health=yellow&v&pretty'

- Explain
  : curl -H 'Content-Type: application/json' -d '{"index": "nginx-2022.02.03", "shard": 0, "primary": true}' 'es.intr:9200/_cluster/allocation/explain?pretty' 

- Explain all indexes
  : GET /_cluster/allocation/explain

- Search
  : curl -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?q=server:web37&pretty"
  : curl -H 'Content-Type: application/json' -d '{"query": {"dis_max": {"queries": [{"match": {"server": "web37"}}, {"match": {"OPERATION_IDENTITY": "LOCAL-SCHED"}}]}}}' -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?pretty&size=1000" | jq -r '.hits.hits[] | ._source.ACTION_IDENTITY'
  : curl -H 'Content-Type: application/json' -d '{"query": {"dis_max": {"queries": [{"match": {"server": "web37"}}, {"match": {"OPERATION_IDENTITY": "LOCAL-SCHED"}}]}}}' -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?pretty&size=2000" | jq --monochrome-output -r '.hits.hits[] | [._source.ACTION_IDENTITY, ._source.log_message] | @tsv' | grep -v 'malware_report\|saved in'
  : curl -H 'Content-Type: application/json' -d '{"query": {"dis_max": {"queries": [{"match": {"server": "web37"}}, {"match": {"OPERATION_IDENTITY": "LOCAL-SCHED"}}, {"match": {"ACTION_IDENTITY": "unix-account.backup.*"}}]}}}' -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?pretty&size=10000" | jq --monochrome-output -r '.hits.hits[] | [._source.ACTION_IDENTITY, ._source.log_message] | @tsv' | wc -l

- Map field
  #+BEGIN_SRC sh
    curl -H "Content-Type: application/json" -XPUT --data-binary \
         '{"properties": {"upload_date": {"type": "date", "format": "yyyyMMdd"}, "title": {"type": "text", "fields":{"keyword":{"type":"keyword","ignore_above":256}}}}}' \
         localhost:9200/youtube-2019.02.10/_mapping/_doc
  #+END_SRC

- Import JSON to Elasticsearch
  : cat /tmp/dio.txt | jq -c '.entries[] | { index: { "_index": "youtube", "_type": "_doc", _id: .id }}, { upload_date: .upload_date, channel_id: .channel_id, title: .title, webpage_url: .webpage_url_basename }' | curl -H "Content-Type: application/json" -XPOST localhost:9200/_bulk --data-binary @-

- Download YouTube channel JSON
  : youtube-dl --ignore-errors -J https://www.youtube.com/user/gotbletu/videos > /tmp/gotbletu.txt

- Create backup repository
  : curl -H "Content-Type: application/json" -XPUT 'http://localhost:9200/_snapshot/youtubee": "fs", "settings": {"compress": true, "location": "/mnt/backup"}}'

- Backup Index 
  : curl -H "Content-Type: application/json" -XPUT 'http://localhost:9200/_snapshot/youtube_fs_backup/snapshot_1?wait_for_completion=true' -d '{"indices": "youtube", "ignore_unavailable": true, "include_global_state": false}'

- Create alias
  : curl -X POST "localhost:9200/_aliases" -H 'Content-Type: application/json' -d'{"actions":[{"add":{"index":"yt-game","alias":"yt"}}]}'

- Reindex
  #+begin_example
    import elasticsearch
    import elasticsearch.helpers

    elastic = elasticsearch.Elasticsearch([{"host": "localhost", "port": 9200}])

    elasticsearch.helpers.reindex(client=elastic, target_client=elastic, source_index="youtube-gaming", target_index="yt-game")
  #+end_example

- Watermark
#+begin_example
  curl -X PUT "es.intr:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'{"transient": {"cluster.routing.allocation.disk.watermark.low": "25gb", "cluster.routing.allocation.disk.watermark.high": "15gb", "cluster.routing.allocation.disk.watermark.flood_stage": "5gb"}}'
#+end_example

- [[https://groups.google.com/g/wazuh/c/lc-NvBVAQcI][Increase number of shards per node]]

  : $ curl -X PUT opensearch.home/_cluster/settings -H "Content-Type: application/json" -d '{ "persistent": { "cluster.max_shards_per_node": "3000" } }'
  # outputs
  : {"acknowledged":true,"persistent":{"cluster":{"max_shards_per_node":"3000"}},"transient":{}}
  
* WIP

oleg@guixsd ~$ curl -H 'Content-Type: application/json' -d '{"query": {"match": {"server": "web37", "OPERATION_IDENTITY": "LOCAL-SCHED"}}}' -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?pretty" 
{
  "error" : {
    "root_cause" : [
      {
        "type" : "parsing_exception",
        "reason" : "[match] query doesn't support multiple fields, found [server] and [OPERATION_IDENTITY]",
        "line" : 1,
        "col" : 63
      }
    ],
    "type" : "parsing_exception",
    "reason" : "[match] query doesn't support multiple fields, found [server] and [OPERATION_IDENTITY]",
    "line" : 1,
    "col" : 63
  },
  "status" : 400
}

curl -H 'Content-Type: application/json' -d '{"query": {"bool": {"must": {"term": {"server": "web37"}}}}}' -s -X GET "elastic.intr:9200/logstash-te-2020.02.28/_search?pretty" 

* Cluster

- health
  : curl -XGET 'http://127.0.0.1:9200/_cluster/health?pretty'

- cluster_uuid
  : curl -XGET 'http://localhost:9200/_cluster/state/master_node?pretty'

- cluster nodes
  : curl -XGET 'http://localhost:9200/_cluster/state/nodes?pretty'

- drain node
  : curl -XPUT localhost:9200/_cluster/settings -H 'Content-Type: application/json' -d '{"transient" :{"cluster.routing.allocation.exclude._ip" : "172.16.103.69"}}'
  : {"acknowledged":true,"persistent":{},"transient":{"cluster":{"routing":{"allocation":{"exclude":{"_ip":"172.16.103.69"}}}}}}

#+begin_example
  oleg@guixsd ~$ curl -s es.intr:9200/_cat/shards?pretty  | grep kvm15
  logstash-payment-2021.05.03       0 p STARTED         985    237kb 172.16.103.101 kvm15-master
  logstash-payment-2021.09.17       0 p STARTED        2014  367.4kb 172.16.103.101 kvm15-master
  .monitoring-es-6-2021.04.14       0 r STARTED        8637      3mb 172.16.103.101 kvm15-master
  .monitoring-es-6-2021.11.01       0 r STARTED        8635    3.2mb 172.16.103.101 kvm15-master
  .monitoring-es-6-2020.07.19       0 r STARTED        8639      3mb 172.16.103.101 kvm15-master
  .monitoring-es-6-2021.07.24       0 r STARTED        8637    2.9mb 172.16.103.101 kvm15-master
  cerb_message_content              2 r RELOCATING  2220954      3gb 172.16.103.69  es2-master -> 172.16.103.101 QPHQ1pd4R6qVOuTuXJbwMQ kvm15-master
  .monitoring-es-6-2019.02.19       0 r STARTED        8634    2.9mb 172.16.103.101 kvm15-master
  payment-listeners-2021.11.24      0 p STARTED          16   38.8kb 172.16.103.101 kvm15-master
  juniper-2021.12.08                0 p STARTED        9577  748.3kb 172.16.103.101 kvm15-master
  logstash-mail-2021.12.03          0 p RELOCATING  7697918  915.1mb 172.16.103.69  es2-master -> 172.16.103.101 QPHQ1pd4R6qVOuTuXJbwMQ kvm15-master
  .monitoring-es-6-2020.05.21       0 r STARTED        8639      3mb 172.16.103.101 kvm15-master
#+end_example

- opensearch compatible with filebeat oss
  : curl -XPUT -H 'Content-Type: application/json' -d '{"persistent":{"compatibility":{"override_main_response_version":true}}}' -k -u admin:PASSWORD https://opensearch-cluster-master.opensearch:9200/_cluster/settings

- disk watermark
#+begin_example
  curl -X PUT "es.intr:9200/_cluster/settings?pretty" -H 'Content-Type: application/json' -d'
  {
    "transient": {
      "cluster.routing.allocation.disk.watermark.low": "100gb",
      "cluster.routing.allocation.disk.watermark.high": "50gb",
      "cluster.routing.allocation.disk.watermark.flood_stage": "10gb"

    }
  }
  '
#+end_example

- nodes stats
  : curl es.intr:9200/_nodes/stats

- nodes disks
  : curl -XGET 'http://es.intr:9200/_cat/allocation?v'

** es3
#+begin_example
  cluster.name: mjlogger

  http.port: 9200
  transport.tcp.port: 9300

  node.name: "staff-vote-only"
  node.data: false
  node.master: true
  node.ingest: true

  path.repo: ["/home/elasticsearch_backups"]
  xpack.security.enabled: false

  discovery.zen.minimum_master_nodes: 2
  discovery.zen.ping.unicast.hosts: [ "172.16.103.68", "172.16.103.69", "172.16.103.112" ]
#+end_example

* Tools

- [[https://github.com/binwiederhier/elastictl][binwiederhier/elastictl: Simple tool to import/export Elasticsearch indices into a file, and/or reshard an index]]
- [[https://github.com/codenoid/elastis][codenoid/elastis: Tool for Export / Dump / Import / Copy Elastic/Open Search indexes data]]
- [[https://github.com/Cyb3rWard0g/HELK][Cyb3rWard0g/HELK: The Hunting ELK]]
- [[https://github.com/elastic/cloud-on-k8s][elastic/cloud-on-k8s: Elastic Cloud on Kubernetes]]
- [[https://github.com/elastic/otel-profiling-agent][elastic/otel-profiling-agent: The production-scale datacenter profiler (C/C++, Go, Rust, Python, Java, NodeJS, PHP, Ruby, Perl, ...)]]
- [[https://github.com/flant/elasticsearch-extractor][flant/elasticsearch-extractor: Simple web UI to extract any index from Elasticsearch snapshot into repository.]]
- [[https://github.com/LGUG2Z/elasdx][LGUG2Z/elasdx: An ElasticSearch index template updating, reindexing and cleanup tool]]
- [[https://github.com/medcl/esm][medcl/esm: An Elasticsearch Migration Tool.]]
- [[https://github.com/Netflix/Raigad][Netflix/Raigad: Co-Process for backup/recovery, Auto Deployments and Centralized Configuration management for ElasticSearch]]
- [[https://github.com/StationA/esx][StationA/esx: CLI for streaming I/O with Elasticsearch]]

* Alternatives

- [[https://github.com/valeriansaliou/sonic][valeriansaliou/sonic: ü¶î Fast, lightweight & schema-less search backend. An alternative to Elasticsearch that runs on a few MBs of RAM.]]
- [[https://github.com/prabhatsharma/zinc][prabhatsharma/zinc: Zinc Search engine. A lightweight alternative to elasticsearch that requires minimal resources, written in Go.]]

* Kibana
- [[https://habr.com/ru/company/citymobil/blog/521802/][–°–æ–∑–¥–∞–Ω–∏–µ Dashboard –≤ Kibana –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ª–æ–≥–æ–≤ / –ë–ª–æ–≥ –∫–æ–º–ø–∞–Ω–∏–∏ –°–∏—Ç–∏–º–æ–±–∏–ª / –•–∞–±—Ä]]

* Misc
- [[https://www.google.com/search?q=elastic+list+replicate+specific+shards&hl=en][elastic list replicate specific shards - Google Search]]
- [[https://logz.io/blog/elasticsearch-cheat-sheet/][A Useful Elasticsearch Cheat Sheet in Times of Trouble | Logz.io]]
- [[https://stackoverflow.com/questions/15694724/shards-and-replicas-in-elasticsearch][full text search - Shards and replicas in Elasticsearch - Stack Overflow]]
- [[https://opster.com/blogs/elasticsearch-shards-and-replicas-getting-started-guide/][Elasticsearch Shards and Replicas getting started guide - Opster]]
- [[https://linuxhint.com/elasticsearch-shard-list/][Elasticsearch Shard List]]
- [[https://www.elastic.co/guide/en/elasticsearch/reference/6.6/cat-shards.html][cat shards | Elasticsearch Guide [6.6] | Elastic]]
- [[https://github.com/dadoonet/fscrawler][dadoonet/fscrawler: Elasticsearch File System Crawler (FS Crawler)]]

* Libraries
- [[https://github.com/bitemyapp/bloodhound][bitemyapp/bloodhound: Haskell Elasticsearch client and query DSL]]
